{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/giuliocapecchi/IR_project/blob/main/IR_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch matplotlib nltk tqdm gdown ir_datasets humanize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download and prepare the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_collection can be one of [\"vaswani\", \"msmarco\", \"covid\"]\n",
    "\n",
    "chosen_collection = \"vaswani\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import ir_datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if chosen_collection not in [\"vaswani\", \"msmarco\"]:\n",
    "    raise ValueError(\"chosen_collection must be one of ['vaswani', 'msmarco']\")\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "\n",
    "    os.makedirs('./collection/msmarco', exist_ok=True)\n",
    "\n",
    "    url_collection = 'https://drive.google.com/uc?id=1_wXJjiwdgc9Kpt7o7atP8oWe-U4Z56hn'\n",
    "    \n",
    "    if not os.path.exists('./collection/msmarco/msmarco.tsv'):\n",
    "        gdown.download(url_collection, './collection/msmarco/msmarco.tsv', quiet=False)\n",
    "    \n",
    "    \"\"\"os.makedirs('./pickles', exist_ok=True)\n",
    "    if not os.path.exists('./pickles/stats.pkl'):\n",
    "        gdown.download(url_stats, './pickles/stats.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/lex.pkl'):\n",
    "        gdown.download(url_lex, './pickles/lex.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/inv.pkl'):\n",
    "        gdown.download(url_inv, './pickles/inv.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/doc.pkl'):\n",
    "        gdown.download(url_doc, './pickles/doc.pkl', quiet=False)\"\"\"\n",
    "\n",
    "elif chosen_collection == \"vaswani\":\n",
    "    os.makedirs('./collection/vaswani', exist_ok=True)\n",
    "\n",
    "    vaswani_dataset = ir_datasets.load(chosen_collection)\n",
    "    docs = list(vaswani_dataset.docs_iter())\n",
    "    df = pd.DataFrame(docs)\n",
    "    df['doc_id'] = (df['doc_id'].astype(int) - 1).astype(str)\n",
    "    # rimuovi i \\n da ogni documento\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    if not os.path.exists('./collection/vaswani/vaswani.tsv'):\n",
    "        df.to_csv('./collection/vaswani/vaswani.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard preprocessing but with the usage of the *PyStemmer* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import Stemmer # PyStemmer\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "STEMMER = Stemmer.Stemmer('english')\n",
    "# stemmer = nltk.stem.PorterStemmer().stem # much slower than PyStemmer\n",
    "\n",
    "\n",
    "def preprocess(s):\n",
    "    # lowercasing\n",
    "    s = s.lower()\n",
    "    # ampersand and special chars\n",
    "    s = re.sub(r\"[‘’´“”–-]\", \"'\", s.replace(\"&\", \" and \")) # this replaces & with 'and' and normalises quotes\n",
    "    # acronyms\n",
    "    s = re.sub(r\"\\.(?!(\\S[^. ])|\\d)\", \"\", s) # this removes dots that are not part of an acronym\n",
    "    # remove punctuation\n",
    "    s = s.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "    # strip whitespaces\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # tokenisation\n",
    "    tokens = [t for t in s.split() if t not in STOPWORDS]\n",
    "    # stemming\n",
    "    return STEMMER.stemWords(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def profile(f):\n",
    "    def f_timer(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        ms = (end - start) * 1000\n",
    "        print(f\"{f.__name__} ({ms:.3f} ms)\")\n",
    "        return result\n",
    "    return f_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import humanize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def print_pickled_size(var_name, var):\n",
    "    # If the 'tmp' directory does not exist, we first create it\n",
    "    os.makedirs('./tmp', exist_ok=True)\n",
    "    with open(f\"./tmp/{var_name}.pickle\", 'wb') as f:\n",
    "        pickle.dump(var, f)\n",
    "    print(f'{var_name} requires {humanize.naturalsize(os.path.getsize(f\"./tmp/{var_name}.pickle\"))}')\n",
    "    os.remove(f\"./tmp/{var_name}.pickle\")\n",
    "    os.removedirs('./tmp')\n",
    "\n",
    "\n",
    "def vbyte_encode(number):\n",
    "    bytes_list = bytearray()\n",
    "    while True:\n",
    "        byte = number & 0x7F # Prendi i 7 bit meno significativi -> 0111 1111 = 0x7F\n",
    "        number >>= 7 # Shifta a destra di 7 bit\n",
    "        if number:\n",
    "            bytes_list.append(byte) # Aggiungo i 7 bit al risultato\n",
    "        else:\n",
    "            bytes_list.append(0x80 | byte) # Aggiungo i 7 bit con il bit di continuazione, 0x80 = 1000 0000\n",
    "            break\n",
    "    return bytes(bytes_list)\n",
    "\n",
    "def vbyte_decode(bytes_seq):\n",
    "    number = 0\n",
    "    for i, byte in enumerate(bytes_seq):\n",
    "        number |= (byte & 0x7F) << (7 * i)\n",
    "        if byte & 0x80:\n",
    "            break\n",
    "    return number\n",
    "\n",
    "def decode_concatenated_vbyte(encoded_bytes):\n",
    "    decoded_numbers = []\n",
    "    current_number = 0\n",
    "    shift_amount = 0\n",
    "    \n",
    "    for byte in encoded_bytes:\n",
    "        if byte & 0x80:  # Bit di continuazione trovato, fine del numero\n",
    "            current_number |= (byte & 0x7F) << shift_amount\n",
    "            decoded_numbers.append(current_number)\n",
    "            current_number = 0\n",
    "            shift_amount = 0\n",
    "        else:  # Continuo a comporre il numero\n",
    "            current_number |= (byte & 0x7F) << shift_amount\n",
    "            shift_amount += 7\n",
    "    \n",
    "    return decoded_numbers\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def compress_index(lexicon, inv_d, inv_f):    \n",
    "    compressed_inv_d = {}\n",
    "    compressed_inv_f = {}\n",
    "\n",
    "    for term, (termid, df, _) in tqdm(lexicon.items(), desc=\"Compressing lists\", unit=\"term\"):\n",
    "        encoded_d = bytearray()\n",
    "        for x in inv_d[termid]:\n",
    "            encoded_d.extend(vbyte_encode(x)) \n",
    "        assert decode_concatenated_vbyte(encoded_d) == inv_d[termid]\n",
    "        compressed_inv_d[termid] = encoded_d\n",
    "\n",
    "        encoded_f = bytearray()\n",
    "        for x in inv_f[termid]:\n",
    "            encoded_f.extend(vbyte_encode(x))\n",
    "        assert decode_concatenated_vbyte(encoded_f) == inv_f[termid]\n",
    "        compressed_inv_f[termid] = encoded_f\n",
    "\n",
    "    return compressed_inv_d, compressed_inv_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def build_index(filepath, batch_size=10000):\n",
    "    total_documents = sum(1 for _ in open(filepath)) # get total number of documents\n",
    "\n",
    "    lexicon = {}\n",
    "    inv_d = {}\n",
    "    inv_f = {}\n",
    "    doc_index = []\n",
    "    total_dl = 0\n",
    "    num_docs = 0\n",
    "    termid = 0\n",
    "\n",
    "    with open(filepath, 'r') as file:        \n",
    "        batch = []\n",
    "        \n",
    "        with tqdm(total=total_documents, desc=\"Processing documents\", unit=\"doc\") as pbar:\n",
    "            for line in file:\n",
    "                batch.append(line.strip())\n",
    "                \n",
    "                # when the batch is full, we process it\n",
    "                if len(batch) >= batch_size:\n",
    "                    for line in batch:\n",
    "                        doc_id, text = line.split('\\t', 1) # '1' specifies the number of splits\n",
    "                        doc_id = int(doc_id)\n",
    "                        tokens = preprocess(text)\n",
    "                        token_tf = Counter(tokens)\n",
    "\n",
    "                        for token, tf in token_tf.items():\n",
    "                            if token not in lexicon:\n",
    "                                lexicon[token] = [termid, 0, 0] # termid, df, tf\n",
    "                                inv_d[termid], inv_f[termid] = [], [] # docids, freqs\n",
    "                                termid += 1\n",
    "                            token_id = lexicon[token][0]  # get termid\n",
    "                            inv_d[token_id].append(doc_id)  # add doc_id to the list of documents containing the term\n",
    "                            inv_f[token_id].append(tf)  # add term frequency for this doc\n",
    "                            lexicon[token][1] += 1  # increment document frequency (df)\n",
    "                            lexicon[token][2] += tf  # increment total term frequency (tf)\n",
    "\n",
    "                        doclen = len(tokens)\n",
    "                        doc_index.append((str(doc_id), doclen))\n",
    "                        total_dl += doclen\n",
    "                        num_docs += 1                    \n",
    "                    # update progress bar for each processed document\n",
    "                    pbar.update(len(batch))\n",
    "                    batch = []\n",
    "\n",
    "            # process the remaining documents in the last batch\n",
    "            if batch:\n",
    "                for line in batch:\n",
    "                    doc_id, text = line.split('\\t', 1)\n",
    "                    doc_id = int(doc_id)\n",
    "                    tokens = preprocess(text)\n",
    "                    token_tf = Counter(tokens)\n",
    "\n",
    "                    for token, tf in token_tf.items():\n",
    "                        if token not in lexicon:\n",
    "                            lexicon[token] = [termid, 0, 0]\n",
    "                            inv_d[termid], inv_f[termid] = [], []\n",
    "                            termid += 1\n",
    "                        token_id = lexicon[token][0]  # get termid\n",
    "                        inv_d[token_id].append(doc_id)  # get doc_id to the list of documents containing the term\n",
    "                        inv_f[token_id].append(tf)  # get term frequency for this doc\n",
    "                        lexicon[token][1] += 1  # increment document frequency (df)\n",
    "                        lexicon[token][2] += tf  # increment total term frequency (tf)\n",
    "\n",
    "                    doclen = len(tokens)\n",
    "                    doc_index.append((str(doc_id), doclen))\n",
    "                    total_dl += doclen\n",
    "                    num_docs += 1                    \n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    stats = {\n",
    "        'num_docs': num_docs,\n",
    "        'num_terms': len(lexicon),\n",
    "        'num_tokens': total_dl,\n",
    "    }\n",
    "    return lexicon, {'docids': inv_d, 'freqs': inv_f}, doc_index, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import bisect\n",
    "\n",
    "\n",
    "class InvertedIndex:\n",
    "\n",
    "    class PostingListIterator:\n",
    "        def __init__(self, docids, freqs, doc):\n",
    "            self.docids = docids\n",
    "            self.freqs = freqs\n",
    "            self.pos = 0\n",
    "            self.doc = doc\n",
    "            self.total_docs_number = len(doc)\n",
    "\n",
    "\n",
    "        def docid(self):\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            return self.docids[self.pos]\n",
    "\n",
    "\n",
    "        ###################################################################################\n",
    "        def score(self): # TODO : check if correct, this is TF-IDF score\n",
    "            \"\"\"\n",
    "            Calculate TF-IDF score of the current document in the posting list.\n",
    "            \"\"\"\n",
    "            if self.is_end_list():\n",
    "                return math.inf \n",
    "            \n",
    "            tf = self.freqs[self.pos]\n",
    "                        \n",
    "            if tf > 0:\n",
    "                wtd = 1 + math.log(tf)\n",
    "            else:\n",
    "                wtd = 0 # avoid log(0)\n",
    "            \n",
    "            df = self.len()  # document frequency\n",
    "            if df > 0:\n",
    "                idf = math.log(self.total_docs_number / df)\n",
    "            else:\n",
    "                idf = 0  # avoid log(0)\n",
    "            \n",
    "            # finally calculate tf-idf score\n",
    "            tfidf = wtd * idf\n",
    "\n",
    "            return tfidf\n",
    "\n",
    "        ###################################################################################\n",
    "\n",
    "        def score_bm25(self): # TODO: check if correct. Also at the moment it is not used\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            else:\n",
    "                # Parametri standard di BM25\n",
    "                b = 0.75\n",
    "                k_1 = 1.5\n",
    "                \n",
    "                # Lunghezza del documento corrente\n",
    "                dl = self.doc[self.docid()][1]\n",
    "                \n",
    "                # Lunghezza media del documento (deve essere calcolata globalmente)\n",
    "                avdl = 25.09  # Assicurati di calcolare avdl correttamente\n",
    "                \n",
    "                # Calcola la frequenza del termine nel documento\n",
    "                tf = self.freqs[self.pos]\n",
    "                \n",
    "                # Numero totale di documenti nella collezione\n",
    "                N = self.total_docs_number\n",
    "                \n",
    "                # Numero di documenti che contengono il termine\n",
    "                n = self.len()  # document frequency\n",
    "                \n",
    "                # Calcola l'IDF\n",
    "                idf = math.log((N - n + 0.5) / (n + 0.5) + 1)\n",
    "                \n",
    "                # Calcola la normalizzazione del TF\n",
    "                norm_tf = (tf * (k_1 + 1)) / (tf + k_1 * (1 - b + b * (dl / avdl)))\n",
    "                \n",
    "                # Calcola il punteggio BM25\n",
    "                rsv_bm25 = idf * norm_tf\n",
    "                \n",
    "                return rsv_bm25\n",
    "            \n",
    "            ###################################################################################\n",
    "\n",
    "        def next(self, target=None):\n",
    "            if not target:\n",
    "                if not self.is_end_list():\n",
    "                    self.pos += 1\n",
    "            else:\n",
    "                if target > self.docid():\n",
    "                    self.pos = bisect.bisect_left(self.docids, target, self.pos)\n",
    "\n",
    "        def is_end_list(self):\n",
    "            return self.pos == len(self.docids)\n",
    "\n",
    "\n",
    "        def len(self):\n",
    "            return len(self.docids)\n",
    "        \n",
    "\n",
    "    def __init__(self, lex, inv, doc, stats):\n",
    "        self.lexicon = lex\n",
    "        self.inv = inv\n",
    "        self.doc = doc\n",
    "        self.stats = stats\n",
    "\n",
    "    def num_docs(self):\n",
    "        return self.stats['num_docs']\n",
    "\n",
    "    def get_posting(self, termid):\n",
    "        return InvertedIndex.PostingListIterator( self.inv['docids'][termid], self.inv['freqs'][termid], self.doc)\n",
    "    \n",
    "\n",
    "    def get_termids(self, tokens):\n",
    "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
    "\n",
    "    def get_postings(self, termids):\n",
    "        return [self.get_posting(termid) for termid in termids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# import pstats\n",
    "\n",
    "# cProfile.run(\"build_index('./vaswani.tsv')\", \"output.prof\")\n",
    "# p = pstats.Stats(\"output.prof\")\n",
    "# p.sort_stats(\"cumtime\").print_stats(10)\n",
    "# os.remove(\"output.prof\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the index on the chosen collection \n",
    "\n",
    "Now build up the index for the chosen collection. It is built only if a pickled version of its components doesn't exist already :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b2a56798ae4396b912261b1ba8ae14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/11429 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di documenti: 11429\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# If the 'pickles' directory does not exist, we first create it\n",
    "os.makedirs('./pickles', exist_ok=True)\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "    try: # try to open the pickled files, else build the index\n",
    "        with open('./pickles/inv_index.pkl', 'rb') as f:\n",
    "            inv_index = pickle.load(f)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        lex, inv, doc, stats = build_index('./collection/'+chosen_collection + '/'+chosen_collection+'.tsv')\n",
    "\n",
    "        # Save the lexicon, inverted lists, and document index to disk\n",
    "        with open('./pickles/lex.pkl', 'wb') as f:\n",
    "            pickle.dump(lex, f)\n",
    "        with open('./pickles/inv.pkl', 'wb') as f:\n",
    "            pickle.dump(inv, f)\n",
    "        with open('./pickles/doc.pkl', 'wb') as f:\n",
    "            pickle.dump(doc, f)\n",
    "        with open('./pickles/stats.pkl', 'wb') as f:\n",
    "            pickle.dump(stats, f)\n",
    "                    \n",
    "        # Compress the inverted lists\n",
    "        #inv['docids'], inv['freqs'] = compress_index(lex, inv['docids'], inv['freqs'])\n",
    "        \n",
    "        inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "        with open('./pickles/inv_index.pkl', 'wb') as f:\n",
    "            pickle.dump(inv_index, f)\n",
    "else:\n",
    "    lex, inv, doc, stats = build_index('./collection/'+chosen_collection + '/'+chosen_collection+'.tsv')\n",
    "    inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "\n",
    "\n",
    "print(f\"Numero di documenti: {inv_index.num_docs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a test collection\n",
    "# test_collection = [\n",
    "#     \"0\\tterm1 term2 term3\",\n",
    "#     \"1\\tterm2 term3 term4\",\n",
    "#     \"2\\tterm1 term4 term5\",\n",
    "#     \"3\\tterm3 term5 term6\",\n",
    "#     \"4\\tterm1 term2 term3\",\n",
    "# ]\n",
    "\n",
    "# # Write the fake collection to a temporary file\n",
    "# with open('./collection/test_collection.tsv', 'w') as f:\n",
    "#     for line in test_collection:\n",
    "#         f.write(line + '\\n')\n",
    "\n",
    "# # Call the build_index function on the test collection\n",
    "# lex, inv, doc, stats = build_index('./collection/test_collection.tsv')\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Lexicon:\", lex)\n",
    "# print(\"Inverted Index (docids):\", inv['docids'])\n",
    "# print(\"Inverted Index (freqs):\", inv['freqs'])\n",
    "# print(\"Document Index:\", doc)\n",
    "# print(\"Statistics:\", stats)\n",
    "\n",
    "# inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "\n",
    "# query = \"term1 term2\"\n",
    "# termids = inv_index.get_termids(query.split())\n",
    "# postings = inv_index.get_postings(termids)\n",
    "# print(f\"Query: '{query}', TermID: {termids}\")\n",
    "# for posting in postings:\n",
    "#     while not posting.is_end_list():\n",
    "#         print(f\"docid: {posting.docid()}, score: {posting.score_bm25()}\")\n",
    "#         posting.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_pickled_size('inv_index', inv_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download and prepare queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  93\n",
      "Number of relevance judgments:  2083\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "if chosen_collection not in [\"vaswani\", \"msmarco\"]:\n",
    "    raise ValueError(\"chosen_collection must be one of ['vaswani', 'msmarco']\")\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "    if not os.path.exists('./collection/msmarco/msmarco-queries.tsv'):\n",
    "        url = 'https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz'\n",
    "        gdown.download(url, './collection/msmarco/msmarco-test2019-queries.tsv.gz', quiet=False)\n",
    "        with gzip.open('./collection/msmarco/msmarco-test2019-queries.tsv.gz', 'rt') as f_in:\n",
    "            with open('./collection/msmarco/msmarco-queries.tsv', 'w') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "        os.remove('./collection/msmarco/msmarco-test2019-queries.tsv.gz') # delete the compressed file\n",
    "    queries = pd.read_csv('./collection/msmarco/msmarco-queries.tsv', sep='\\t', header=None)\n",
    "    queries.columns = ['qid', 'query']\n",
    "    print(\"Number of queries: \",len(queries))\n",
    "\n",
    "    if not os.path.exists('./collection/msmarco/msmarco-qrels.txt'):\n",
    "        url = 'https://trec.nist.gov/data/deep/2019qrels-pass.txt'\n",
    "        gdown.download(url, './collection/msmarco/msmarco-qrels.txt', quiet=False)\n",
    "    qrels = pd.read_csv('./collection/msmarco/msmarco-qrels.txt', sep=' ', header=None)\n",
    "    qrels.columns = ['qid', 'Q0', 'docid', 'rating']\n",
    "    print(\"Number of relevance judgments: \",len(qrels))\n",
    "\n",
    "\n",
    "elif chosen_collection == \"vaswani\":\n",
    "    queries = pd.DataFrame(vaswani_dataset.queries_iter())\n",
    "    queries.columns = ['qid', 'query']\n",
    "    print(\"Number of queries: \",len(list(vaswani_dataset.queries_iter()))) \n",
    "    if not os.path.exists('./collection/vaswani/vaswani-queries.tsv'):\n",
    "        queries.to_csv('./collection/vaswani/vaswani-queries.tsv', sep='\\t', header=False, index=False)\n",
    "    qrels = pd.DataFrame(vaswani_dataset.qrels_iter()) \n",
    "    qrels.columns = ['qid', 'docid', 'relevance', 'iteration']\n",
    "    qrels['docid'] = (qrels['docid'].astype(int) - 1).astype(str) # convert to 0-based indexing\n",
    "\n",
    "    if not os.path.exists('./collection/vaswani/vaswani-qrels.txt'):\n",
    "        qrels.to_csv('./collection/vaswani/vaswani-qrels.txt', sep='\\t', header=False, index=False)\n",
    "    print(\"Number of relevance judgments: \",len(list(vaswani_dataset.qrels_iter())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of queries is:  93\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class QueriesDataset:\n",
    "    def __init__(self, df):\n",
    "        self.queries = [Query(row.query_id, row.text) for row in df.itertuples()]\n",
    "\n",
    "    def queries_iter(self):\n",
    "        return iter(self.queries)\n",
    "\n",
    "    def queries_count(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def get_query(self, query_id):\n",
    "        return self.queries[query_id]\n",
    "\n",
    "\n",
    "Query = namedtuple('Query', ['query_id', 'text'])\n",
    "queries.columns = ['query_id', 'text']\n",
    "queries_dataset = QueriesDataset(queries)\n",
    "print(\"The number of queries is: \", queries_dataset.queries_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the functions necessary to perform TAAT and DAAT query processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need a TopQueue class, which stores the top  K  (score, docid) tuples, using an heap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class TopQueue:\n",
    "    def __init__(self, k=10, threshold=0.0):\n",
    "        self.queue = []\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.queue)\n",
    "\n",
    "    def would_enter(self, score):\n",
    "        return score > self.threshold\n",
    "\n",
    "    def clear(self, new_threshold=None):\n",
    "        self.queue = []\n",
    "        if new_threshold:\n",
    "            self.threshold = new_threshold\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<{self.size()} items, th={self.threshold} {self.queue}'\n",
    "\n",
    "    def insert(self, docid, score):\n",
    "        if score > self.threshold:\n",
    "            if self.size() >= self.k:\n",
    "                heapq.heapreplace(self.queue, (score, docid))\n",
    "            else:\n",
    "                heapq.heappush(self.queue, (score, docid))\n",
    "            if self.size() >= self.k:\n",
    "                self.threshold = max(self.threshold, self.queue[0][0])\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "#print(sorted(topq.queue, reverse=True)) # print the queue sorted by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def taat(postings, k=10):\n",
    "    A = defaultdict(float)\n",
    "    for posting in postings:\n",
    "        current_docid = posting.docid()\n",
    "        while current_docid != math.inf:\n",
    "            A[current_docid] += posting.score()\n",
    "            posting.next()\n",
    "            current_docid = posting.docid()\n",
    "    top = TopQueue(k)\n",
    "    for docid, score in A.items():\n",
    "        top.insert(docid, score)\n",
    "    return sorted(top.queue, reverse=True)\n",
    "\n",
    "\n",
    "def query_process(query, index):\n",
    "    qtokens = set(preprocess(query))\n",
    "    qtermids = index.get_termids(qtokens)\n",
    "    postings = index.get_postings(qtermids)\n",
    "    return taat(postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def min_docid(postings):\n",
    "    min_docid = math.inf\n",
    "    for p in postings:\n",
    "        if not p.is_end_list():\n",
    "            min_docid = min(p.docid(), min_docid)\n",
    "    return min_docid\n",
    "\n",
    "def daat(postings, k=10):\n",
    "    top = TopQueue(k)\n",
    "    current_docid = min_docid(postings)\n",
    "    while current_docid != math.inf:\n",
    "        score = 0\n",
    "        next_docid = math.inf\n",
    "        for posting in postings:\n",
    "            if posting.docid() == current_docid:\n",
    "                score += posting.score()\n",
    "                posting.next()\n",
    "            if not posting.is_end_list():\n",
    "                next_docid = posting.docid()\n",
    "        top.insert(current_docid, score)\n",
    "        current_docid = next_docid\n",
    "    return sorted(top.queue, reverse=True)\n",
    "\n",
    "def query_process(query, index):\n",
    "    qtokens = set(preprocess(query))\n",
    "    qtermids = index.get_termids(qtokens)\n",
    "    postings = index.get_postings(qtermids)\n",
    "    return daat(postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "@profile\n",
    "def query_processing(queries_iter, fn):\n",
    "    #for q in tqdm(queries_iter, desc=\"Processing queries\", total=queries_dataset.queries_count(), unit=\"query\"):\n",
    "    for q in queries_iter:\n",
    "        query = preprocess(q.text)\n",
    "        termids = inv_index.get_termids(query)\n",
    "        postings = inv_index.get_postings(termids)\n",
    "        res = fn(postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# import pstats\n",
    "\n",
    "# cProfile.run(\"query_processing(queries_dataset.queries_iter(), taat)\", \"./perfm/result.prof\")\n",
    "# p = pstats.Stats(\"./perfm/result.prof\")\n",
    "# p.sort_stats(\"cumtime\").print_stats(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_processing (874.684 ms)\n"
     ]
    }
   ],
   "source": [
    "query_processing(queries_dataset.queries_iter(), taat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_processing (3058.723 ms)\n"
     ]
    }
   ],
   "source": [
    "query_processing(queries_dataset.queries_iter(), daat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relevance assessment (called ***qrel*** in `ir_datasets`) is composed by:\n",
    "* a **topic id** (called *query_id* in `ir_datasets`) as in a topic,\n",
    "* a **docno** (called *doc_id* in `ir_datasets`) as in a document,\n",
    "* a **judgement** (called *relevance* in `ir_datasets`) as a binary or graded relevance judgment/label, and\n",
    "* an **iteration**, **UNUSED** and always equal to the string `'0'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevance judgments:  2083\n"
     ]
    }
   ],
   "source": [
    "# get the qrels for the chosen collection\n",
    "qrels = pd.read_csv('./collection/'+chosen_collection+'/'+chosen_collection+'-qrels.txt', sep='\\t', header=None)\n",
    "qrels.columns = ['query_id', 'doc_id', 'relevance', 'iteration']\n",
    "print(\"Number of relevance judgments: \",len(qrels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_run_file(queries_iter, fn, run_id, output_file):\n",
    "    \"\"\"\n",
    "    Preprocess the queries and write the results to a run file.\n",
    "    :param queries_iter: Query iterator\n",
    "    :param fn: Function to process the postings and return the results in the format (score, docid)\n",
    "    :param run_id: Name identifier for the run\n",
    "    :param output_file: Output run file\n",
    "    \"\"\"\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "    with open(f\"./results/{output_file}\", \"w\") as f:\n",
    "        for q in queries_iter:\n",
    "            topic_id = q.query_id \n",
    "            query = preprocess(q.text)\n",
    "            termids = inv_index.get_termids(query)\n",
    "            postings = inv_index.get_postings(termids)\n",
    "            results = fn(postings, k=100)\n",
    "            \n",
    "            if results:\n",
    "                # Write results to the run file\n",
    "                for rank, (score, docno) in enumerate(results, start=1):\n",
    "                    line = f\"{topic_id}\\tQ0\\t{docno}\\t{rank}\\t{score:.6f}\\t{run_id}\\n\"\n",
    "                    f.write(line)\n",
    "            else:\n",
    "                # Annotate that no results were found for this query\n",
    "                line = f\"{topic_id}\\tQ0\\tNO_RESULTS\\t0\\t0.0\\t{run_id}\\n\"\n",
    "                f.write(line)\n",
    "\n",
    "    print(f\"Run file {output_file} produced successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run file vaswani.run produced successfully.\n"
     ]
    }
   ],
   "source": [
    "create_run_file(queries_dataset.queries_iter(), taat, \"run\", f\"{chosen_collection}.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries in the qrel file:  93\n",
      "Number of queries in the run file:  93\n",
      "Number of 'A':  93\n"
     ]
    }
   ],
   "source": [
    "# open the qrel file and create a 'gold' dictionary that contains for each qid the list of relevant documents\n",
    "gold = {}\n",
    "with open('./collection/vaswani/vaswani-qrels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        qid, docid, rel, _ = line.strip().split('\\t')\n",
    "        qid = int(qid)\n",
    "        docid = int(docid)\n",
    "        if int(rel) > 0:\n",
    "            if qid not in gold:\n",
    "                gold[qid] = []\n",
    "            gold[qid].append(docid)\n",
    "\n",
    "\n",
    "D = list(range(inv_index.num_docs())) # from 0 to number of documents\n",
    "T = list(range(1,len(gold))) # from 1 to number of queries\n",
    "\n",
    "# open the run file and create a 'results' dictionary that contains for each qid the list of retrieved documents\n",
    "results = {}\n",
    "with open('./results/vaswani.run', 'r') as f:\n",
    "    for line in f:\n",
    "        qid, _, docid, rank, score, _ = line.strip().split('\\t')\n",
    "        qid = int(qid)\n",
    "        if docid == 'NO_RESULTS':\n",
    "            docid = -1\n",
    "        else:\n",
    "            docid = int(docid)\n",
    "        if qid not in results:\n",
    "            results[qid] = []\n",
    "        results[qid].append(docid)\n",
    "\n",
    "\n",
    "A = {} # A will contain if the results returned by the IR system are actually relevant\n",
    "for qid in gold:\n",
    "    A[qid] = [1 if d in gold[qid] else 0 for d in D]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of queries in the qrel file: \", len(gold))\n",
    "print(\"Number of queries in the run file: \", len(results))\n",
    "print(\"Number of 'A': \", len(A))\n",
    "\n",
    "# print(\"qrels:\\t\",gold)\n",
    "# print(\"results:\",results)\n",
    "# # stampa i primi 10 elementi di A\n",
    "# print(\"A:\\t\", {k: A[k] for k in list(A)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: F1 = 0.18487394957983191\n",
      "Topic 2: F1 = 0.1391304347826087\n",
      "Topic 3: F1 = 0.25563909774436094\n",
      "Topic 4: F1 = 0.07619047619047618\n",
      "Topic 5: F1 = 0\n",
      "Topic 6: F1 = 0.1090909090909091\n",
      "Topic 7: F1 = 0.5371428571428571\n",
      "Topic 8: F1 = 0.019801980198019802\n",
      "Topic 9: F1 = 0.0392156862745098\n",
      "Topic 10: F1 = 0.10810810810810809\n",
      "Topic 11: F1 = 0.07692307692307693\n",
      "Topic 12: F1 = 0.3597122302158273\n",
      "Topic 13: F1 = 0.31446540880503143\n",
      "Topic 14: F1 = 0.3974358974358974\n",
      "Topic 15: F1 = 0.2878787878787879\n",
      "Topic 16: F1 = 0.09523809523809523\n",
      "Topic 17: F1 = 0.2601626016260163\n",
      "Topic 18: F1 = 0.14159292035398233\n",
      "Topic 19: F1 = 0.24193548387096772\n",
      "Topic 20: F1 = 0.22764227642276424\n",
      "Topic 21: F1 = 0.4133333333333334\n",
      "Topic 22: F1 = 0.3393939393939394\n",
      "Topic 23: F1 = 0.19999999999999998\n",
      "Topic 24: F1 = 0.2877697841726619\n",
      "Topic 25: F1 = 0.3236994219653179\n",
      "Topic 26: F1 = 0.32679738562091504\n",
      "Topic 27: F1 = 0.25\n",
      "Topic 28: F1 = 0.1111111111111111\n",
      "Topic 29: F1 = 0.07207207207207207\n",
      "Topic 30: F1 = 0.09345794392523366\n",
      "Topic 31: F1 = 0.12612612612612614\n",
      "Topic 32: F1 = 0.21238938053097348\n",
      "Topic 33: F1 = 0.1111111111111111\n",
      "Topic 34: F1 = 0.09174311926605504\n",
      "Topic 35: F1 = 0.2769230769230769\n",
      "Topic 36: F1 = 0.07407407407407407\n",
      "Topic 37: F1 = 0.272\n",
      "Topic 38: F1 = 0.17857142857142858\n",
      "Topic 39: F1 = 0.03809523809523809\n",
      "Topic 40: F1 = 0.3255813953488372\n",
      "Topic 41: F1 = 0.21739130434782608\n",
      "Topic 42: F1 = 0.4117647058823529\n",
      "Topic 43: F1 = 0.13084112149532712\n",
      "Topic 44: F1 = 0.12962962962962962\n",
      "Topic 45: F1 = 0.07619047619047618\n",
      "Topic 46: F1 = 0.4081632653061224\n",
      "Topic 47: F1 = 0.3939393939393939\n",
      "Topic 48: F1 = 0.058252427184466014\n",
      "Topic 49: F1 = 0.07476635514018691\n",
      "Topic 50: F1 = 0.019801980198019802\n",
      "Topic 51: F1 = 0.1896551724137931\n",
      "Topic 52: F1 = 0.20800000000000002\n",
      "Topic 53: F1 = 0.10256410256410256\n",
      "Topic 54: F1 = 0.09090909090909091\n",
      "Topic 55: F1 = 0.14159292035398233\n",
      "Topic 56: F1 = 0.15827338129496404\n",
      "Topic 57: F1 = 0.1272727272727273\n",
      "Topic 58: F1 = 0.09090909090909091\n",
      "Topic 59: F1 = 0\n",
      "Topic 60: F1 = 0.058252427184466014\n",
      "Topic 61: F1 = 0.23943661971830987\n",
      "Topic 62: F1 = 0.2809917355371901\n",
      "Topic 63: F1 = 0.30769230769230765\n",
      "Topic 64: F1 = 0.09836065573770492\n",
      "Topic 65: F1 = 0.07692307692307693\n",
      "Topic 66: F1 = 0.07407407407407407\n",
      "Topic 67: F1 = 0.14173228346456693\n",
      "Topic 68: F1 = 0.21052631578947373\n",
      "Topic 69: F1 = 0.1754385964912281\n",
      "Topic 70: F1 = 0.09523809523809523\n",
      "Topic 71: F1 = 0.1652892561983471\n",
      "Topic 72: F1 = 0.30303030303030304\n",
      "Topic 73: F1 = 0.22033898305084748\n",
      "Topic 74: F1 = 0.2727272727272727\n",
      "Topic 75: F1 = 0.6144578313253012\n",
      "Topic 76: F1 = 0.09174311926605504\n",
      "Topic 77: F1 = 0.20967741935483872\n",
      "Topic 78: F1 = 0.16000000000000003\n",
      "Topic 79: F1 = 0.17054263565891473\n",
      "Topic 80: F1 = 0.01769911504424779\n",
      "Topic 81: F1 = 0.07692307692307693\n",
      "Topic 82: F1 = 0.18032786885245902\n",
      "Topic 83: F1 = 0.253968253968254\n",
      "Topic 84: F1 = 0.21138211382113822\n",
      "Topic 85: F1 = 0.018518518518518517\n",
      "Topic 86: F1 = 0.16666666666666669\n",
      "Topic 87: F1 = 0.09345794392523366\n",
      "Topic 88: F1 = 0.09090909090909091\n",
      "Topic 89: F1 = 0.16071428571428573\n",
      "Topic 90: F1 = 0.18604651162790695\n",
      "Topic 91: F1 = 0.32592592592592595\n",
      "Topic 92: F1 = 0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "def precision(results, qrels): # i qrels sono i relevance assesment files\n",
    "    retrieved = len(results)\n",
    "    retrieved_relevant = sum([qrels[d] for d in results])\n",
    "    return retrieved_relevant/retrieved # effettivamente torna\n",
    "\n",
    "def recall(results, qrels):\n",
    "    relevant = sum(qrels)\n",
    "    retrieved_relevant = sum([qrels[d] for d in results])\n",
    "    return retrieved_relevant/relevant\n",
    "\n",
    "def f1_score(results, qrels):\n",
    "    P = precision(results, qrels)\n",
    "    R = recall(results, qrels)\n",
    "    # TODO : rimuovi perchè non esiste che sia zero\n",
    "    if P + R == 0:\n",
    "        return 0\n",
    "    ##########################################\n",
    "    return 2*R*P/(R+P)\n",
    "    \n",
    "for t in T:\n",
    "    print(f'Topic {t}: F1 = {f1_score(results[t], A[t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1 = 0.5652173913043478\n",
      "P@3 = 0.4239130434782608\n",
      "P@5 = 0.3717391304347826\n",
      "P@10 = 0.30869565217391304\n",
      "P@20 = 0.2510869565217391\n",
      "R@1 = 0.037321107090456586\n",
      "R@3 = 0.08939794437335334\n",
      "R@5 = 0.1286306945945357\n",
      "R@10 = 0.19287334802568679\n",
      "R@20 = 0.3014126920954252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precision_at_k(results, qrels, k):\n",
    "    return precision(results[:k], qrels) # prende i primi k risultati e calcola la precisione su questi\n",
    "\n",
    "for k in [1, 3, 5, 10, 20]:\n",
    "    print(f'P@{k} = {np.mean([precision_at_k(results[t], A[t], k) for t in T])}') # media delle precisioni per ogni topic\n",
    "\n",
    "\n",
    "def recall_at_k(results, qrels, k):\n",
    "    return recall(results[:k], qrels)\n",
    "\n",
    "for k in [1, 3, 5, 10, 20]:\n",
    "    print(f'R@{k} = {np.mean([recall_at_k(results[t], A[t], k) for t in T])}') # stessa cosa di prima ma per recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P(rel=2)@5: 0.0, P@5: 0.37204301075268803, AP(rel=2): 0.0, Judged@10: 0.30752688172043, Bpref(rel=2): 0.0, Bpref: 0.5969221205233392, AP: 0.21990222074835353, nDCG@10: 0.3805876017994083}\n"
     ]
    }
   ],
   "source": [
    "import ir_measures\n",
    "from ir_measures import * # import natural measure names\n",
    "\n",
    "chosen_collection = \"vaswani\"\n",
    "qrels = pd.read_csv(f'./collection/{chosen_collection}/{chosen_collection}-qrels.txt', sep='\\t', header=None, names=['query_id', 'doc_id', 'relevance', 'iteration'])\n",
    "qrels['query_id'] = qrels['query_id'].apply(str)\n",
    "qrels['doc_id'] = qrels['doc_id'].apply(str)\n",
    "qrels['relevance'] = qrels['relevance'].apply(int)\n",
    "\n",
    "\n",
    "run_file = list(ir_measures.read_trec_run(f'./results/{chosen_collection}.run'))\n",
    "\n",
    "\n",
    "print(ir_measures.calc_aggregate([P@5, P(rel=2)@5, nDCG@10, AP, AP(rel=2), Bpref, Bpref(rel=2), Judged@10], qrels, run_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric(query_id='1', measure=AP(rel=2), value=0.0)\n",
      "Metric(query_id='1', measure=Bpref(rel=2), value=0.0)\n",
      "Metric(query_id='1', measure=P(rel=2)@5, value=0.0)\n",
      "Metric(query_id='1', measure=nDCG@10, value=0.4666234168001789)\n",
      "Metric(query_id='2', measure=AP(rel=2), value=0.0)\n",
      "Metric(query_id='2', measure=Bpref(rel=2), value=0.0)\n",
      "Metric(query_id='2', measure=P(rel=2)@5, value=0.0)\n",
      "Metric(query_id='2', measure=nDCG@10, value=0.06943122193677727)\n",
      "Metric(query_id='3', measure=AP(rel=2), value=0.0)\n",
      "Metric(query_id='3', measure=Bpref(rel=2), value=0.0)\n"
     ]
    }
   ],
   "source": [
    "# TODO : da rivedere\n",
    "\n",
    "count = 0\n",
    "for metric in ir_measures.iter_calc([P@5, P(rel=2)@5, nDCG@10, AP, AP(rel=2), Bpref, Bpref(rel=2), Judged@10], qrels, run_file):\n",
    "  print(metric)\n",
    "  count += 1\n",
    "  if count >= 10: break # only show top 10 items\n",
    "\n",
    "run_file_p_rel2_5 = {m.query_id: m.value for m in ir_measures.iter_calc([Bpref(rel=2)], qrels, run_file)}\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "qids = list(run_file_p_rel2_5.keys())\n",
    "#ttest_rel([run_file_p_rel2_5[v] for v in qids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6994ee8ff7b465db5286588b42ef943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(RadioButtons(description='Scoring function:', options=('TF-IDF', 'BM25'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d23be147e0a41488ad5cbad709814cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "# UI elements\n",
    "search_bar = widgets.Text(\n",
    "    placeholder='Type in a query...',\n",
    "    description='Search:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    button_style='success',\n",
    "    tooltip='Execute the query',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "score_function_rbtn = widgets.RadioButtons(options=['TF-IDF', 'BM25'], description='Scoring function:', disabled=False)\n",
    "algo_rbtn = widgets.RadioButtons(options=['TAAT', 'DAAT'], description='Algorithm:', disabled=False)\n",
    "_style = widgets.HTML(\n",
    "    \"<style>.widget-radio-box {flex-direction: row !important;}.widget-radio-box\"\n",
    "    \" label{margin:2px !important;width: 100px !important;}</style>\",\n",
    "    layout=widgets.Layout(display=\"none\"),\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "\n",
    "def on_search_click(b):\n",
    "    with output_area:\n",
    "        clear_output()  # clean previous output\n",
    "        query = search_bar.value\n",
    "        if not query.strip():\n",
    "            print(\"Please, type in a query.\")\n",
    "            return\n",
    "        \n",
    "        selected_scoring_function = score_function_rbtn.value\n",
    "        print(f\"Selected scoring function: {selected_scoring_function}\")\n",
    "        # TODO : implement the selected scoring function\n",
    "\n",
    "        selected_algorithm = algo_rbtn.value\n",
    "        print(f\"Selected Algorithm: {selected_algorithm}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # --- QUERY EXECUTION ---\n",
    "        processed_query = preprocess(query)\n",
    "        termids = inv_index.get_termids(processed_query)\n",
    "        postings = inv_index.get_postings(termids)\n",
    "        \n",
    "        if selected_algorithm == 'TAAT':\n",
    "            results = taat(postings)\n",
    "        else:\n",
    "            results = daat(postings)\n",
    "        # ------------------------\n",
    "        elapsed_time = (time.time() - start_time) * 1000 # convert in ms\n",
    "\n",
    "        # finally show the results\n",
    "        print(f\"Found: {len(results)} documents\\n\")\n",
    "        for res in results:\n",
    "            res = (round(res[0], 4), res[1]) # TODO : si potrebbe spostare direttamente nella score function\n",
    "            print(f\" - {res}\")\n",
    "        print(f\"\\nExecution time: {elapsed_time:.2f} ms\")\n",
    "\n",
    "search_button.on_click(on_search_click)\n",
    "# link search button to the enter key\n",
    "search_bar.continuous_update = False\n",
    "search_bar.observe(on_search_click, names='value')\n",
    "\n",
    "top_row = widgets.HBox([score_function_rbtn,_style])\n",
    "middle_row = widgets.HBox([algo_rbtn,_style])\n",
    "bottom_row = widgets.HBox([search_bar, search_button])\n",
    "\n",
    "# finally display the UI\n",
    "display(widgets.VBox([top_row,middle_row, bottom_row]))\n",
    "display(output_area)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mircv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
