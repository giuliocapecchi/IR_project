{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/giuliocapecchi/IR_project/blob/main/IR_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.294725Z",
     "start_time": "2024-11-19T17:27:39.283186Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install torch matplotlib nltk tqdm gdown ir_datasets humanize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download and prepare the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.388287Z",
     "start_time": "2024-11-19T17:27:39.359476Z"
    }
   },
   "outputs": [],
   "source": [
    "# chosen_collection can be one of [\"vaswani\", \"msmarco\", \"covid\"]\n",
    "\n",
    "chosen_collection = \"msmarco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.561923Z",
     "start_time": "2024-11-19T17:27:39.454360Z"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import ir_datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if chosen_collection not in [\"vaswani\", \"msmarco\"]:\n",
    "    raise ValueError(\"chosen_collection must be one of ['vaswani', 'msmarco']\")\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "\n",
    "    os.makedirs('./collection/msmarco', exist_ok=True)\n",
    "\n",
    "    url_collection = 'https://drive.google.com/uc?id=1_wXJjiwdgc9Kpt7o7atP8oWe-U4Z56hn'\n",
    "    \n",
    "    if not os.path.exists('./collection/msmarco/msmarco.tsv'):\n",
    "        gdown.download(url_collection, './collection/msmarco/msmarco.tsv', quiet=False)\n",
    "    \n",
    "    \"\"\"os.makedirs('./pickles', exist_ok=True)\n",
    "    if not os.path.exists('./pickles/stats.pkl'):\n",
    "        gdown.download(url_stats, './pickles/stats.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/lex.pkl'):\n",
    "        gdown.download(url_lex, './pickles/lex.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/inv.pkl'):\n",
    "        gdown.download(url_inv, './pickles/inv.pkl', quiet=False)\n",
    "    if not os.path.exists('./pickles/doc.pkl'):\n",
    "        gdown.download(url_doc, './pickles/doc.pkl', quiet=False)\"\"\"\n",
    "\n",
    "elif chosen_collection == \"vaswani\":\n",
    "    os.makedirs('./collection/vaswani', exist_ok=True)\n",
    "\n",
    "    vaswani_dataset = ir_datasets.load(chosen_collection)\n",
    "    docs = list(vaswani_dataset.docs_iter())\n",
    "    df = pd.DataFrame(docs)\n",
    "    df['doc_id'] = (df['doc_id'].astype(int) - 1).astype(str)\n",
    "    # rimuovi i \\n da ogni documento\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    if not os.path.exists('./collection/vaswani/vaswani.tsv'):\n",
    "        df.to_csv('./collection/vaswani/vaswani.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard preprocessing but with the usage of the *PyStemmer* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.671041Z",
     "start_time": "2024-11-19T17:27:39.649947Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import Stemmer # PyStemmer\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "STEMMER = Stemmer.Stemmer('english')\n",
    "# stemmer = nltk.stem.PorterStemmer().stem # much slower than PyStemmer\n",
    "\n",
    "\n",
    "def preprocess(s):\n",
    "    # lowercasing\n",
    "    s = s.lower()\n",
    "    # ampersand and special chars\n",
    "    s = re.sub(r\"[‘’´“”–-]\", \"'\", s.replace(\"&\", \" and \")) # this replaces & with 'and' and normalises quotes\n",
    "    # acronyms\n",
    "    s = re.sub(r\"\\.(?!(\\S[^. ])|\\d)\", \"\", s) # this removes dots that are not part of an acronym\n",
    "    # remove punctuation\n",
    "    s = s.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "    # strip whitespaces\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # tokenisation\n",
    "    tokens = [t for t in s.split() if t not in STOPWORDS]\n",
    "    # stemming\n",
    "    return STEMMER.stemWords(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.717258Z",
     "start_time": "2024-11-19T17:27:39.705731Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def profile(f):\n",
    "    def f_timer(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        ms = (end - start) * 1000\n",
    "        print(f\"{f.__name__} ({ms:.3f} ms)\")\n",
    "        return result\n",
    "    return f_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.810568Z",
     "start_time": "2024-11-19T17:27:39.782650Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import humanize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def print_pickled_size(var_name, var):\n",
    "    # If the 'tmp' directory does not exist, we first create it\n",
    "    os.makedirs('./tmp', exist_ok=True)\n",
    "    with open(f\"./tmp/{var_name}.pickle\", 'wb') as f:\n",
    "        pickle.dump(var, f)\n",
    "    print(f'{var_name} requires {humanize.naturalsize(os.path.getsize(f\"./tmp/{var_name}.pickle\"))}')\n",
    "    os.remove(f\"./tmp/{var_name}.pickle\")\n",
    "    os.removedirs('./tmp')\n",
    "\n",
    "\n",
    "def vbyte_encode(number):\n",
    "    bytes_list = bytearray()\n",
    "    while True:\n",
    "        byte = number & 0x7F # Prendi i 7 bit meno significativi -> 0111 1111 = 0x7F\n",
    "        number >>= 7 # Shifta a destra di 7 bit\n",
    "        if number:\n",
    "            bytes_list.append(byte) # Aggiungo i 7 bit al risultato\n",
    "        else:\n",
    "            bytes_list.append(0x80 | byte) # Aggiungo i 7 bit con il bit di continuazione, 0x80 = 1000 0000\n",
    "            break\n",
    "    return bytes(bytes_list)\n",
    "\n",
    "def vbyte_decode(bytes_seq):\n",
    "    number = 0\n",
    "    for i, byte in enumerate(bytes_seq):\n",
    "        number |= (byte & 0x7F) << (7 * i)\n",
    "        if byte & 0x80:\n",
    "            break\n",
    "    return number\n",
    "\n",
    "def decode_concatenated_vbyte(encoded_bytes):\n",
    "    decoded_numbers = []\n",
    "    current_number = 0\n",
    "    shift_amount = 0\n",
    "    \n",
    "    for byte in encoded_bytes:\n",
    "        if byte & 0x80:  # Bit di continuazione trovato, fine del numero\n",
    "            current_number |= (byte & 0x7F) << shift_amount\n",
    "            decoded_numbers.append(current_number)\n",
    "            current_number = 0\n",
    "            shift_amount = 0\n",
    "        else:  # Continuo a comporre il numero\n",
    "            current_number |= (byte & 0x7F) << shift_amount\n",
    "            shift_amount += 7\n",
    "    \n",
    "    return decoded_numbers\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def compress_index(lexicon, inv_d, inv_f):    \n",
    "    compressed_inv_d = {}\n",
    "    compressed_inv_f = {}\n",
    "\n",
    "    for term, (termid, df, _) in tqdm(lexicon.items(), desc=\"Compressing lists\", unit=\"term\"):\n",
    "        encoded_d = bytearray()\n",
    "        for x in inv_d[termid]:\n",
    "            encoded_d.extend(vbyte_encode(x)) \n",
    "        assert decode_concatenated_vbyte(encoded_d) == inv_d[termid]\n",
    "        compressed_inv_d[termid] = encoded_d\n",
    "\n",
    "        encoded_f = bytearray()\n",
    "        for x in inv_f[termid]:\n",
    "            encoded_f.extend(vbyte_encode(x))\n",
    "        assert decode_concatenated_vbyte(encoded_f) == inv_f[termid]\n",
    "        compressed_inv_f[termid] = encoded_f\n",
    "\n",
    "    return compressed_inv_d, compressed_inv_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.889433Z",
     "start_time": "2024-11-19T17:27:39.848182Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def build_index(filepath, batch_size=10000):\n",
    "    total_documents = sum(1 for _ in open(filepath)) # get total number of documents\n",
    "\n",
    "    lexicon = {}\n",
    "    inv_d = {}\n",
    "    inv_f = {}\n",
    "    doc_index = []\n",
    "    total_dl = 0\n",
    "    num_docs = 0\n",
    "    termid = 0\n",
    "\n",
    "    with open(filepath, 'r') as file:        \n",
    "        batch = []\n",
    "        \n",
    "        with tqdm(total=total_documents, desc=\"Processing documents\", unit=\"doc\") as pbar:\n",
    "            for line in file:\n",
    "                batch.append(line.strip())\n",
    "                \n",
    "                # when the batch is full, we process it\n",
    "                if len(batch) >= batch_size:\n",
    "                    for line in batch:\n",
    "                        doc_id, text = line.split('\\t', 1) # '1' specifies the number of splits\n",
    "                        doc_id = int(doc_id)\n",
    "                        tokens = preprocess(text)\n",
    "                        token_tf = Counter(tokens)\n",
    "\n",
    "                        for token, tf in token_tf.items():\n",
    "                            if token not in lexicon:\n",
    "                                lexicon[token] = [termid, 0, 0] # termid, df, tf\n",
    "                                inv_d[termid], inv_f[termid] = [], [] # docids, freqs\n",
    "                                termid += 1\n",
    "                            token_id = lexicon[token][0]  # get termid\n",
    "                            inv_d[token_id].append(doc_id)  # add doc_id to the list of documents containing the term\n",
    "                            inv_f[token_id].append(tf)  # add term frequency for this doc\n",
    "                            lexicon[token][1] += 1  # increment document frequency (df)\n",
    "                            lexicon[token][2] += tf  # increment total term frequency (tf)\n",
    "\n",
    "                        doclen = len(tokens)\n",
    "                        doc_index.append((str(doc_id), doclen))\n",
    "                        total_dl += doclen\n",
    "                        num_docs += 1                    \n",
    "                    # update progress bar for each processed document\n",
    "                    pbar.update(len(batch))\n",
    "                    batch = []\n",
    "\n",
    "            # process the remaining documents in the last batch\n",
    "            if batch:\n",
    "                for line in batch:\n",
    "                    doc_id, text = line.split('\\t', 1)\n",
    "                    doc_id = int(doc_id)\n",
    "                    tokens = preprocess(text)\n",
    "                    token_tf = Counter(tokens)\n",
    "\n",
    "                    for token, tf in token_tf.items():\n",
    "                        if token not in lexicon:\n",
    "                            lexicon[token] = [termid, 0, 0]\n",
    "                            inv_d[termid], inv_f[termid] = [], []\n",
    "                            termid += 1\n",
    "                        token_id = lexicon[token][0]  # get termid\n",
    "                        inv_d[token_id].append(doc_id)  # get doc_id to the list of documents containing the term\n",
    "                        inv_f[token_id].append(tf)  # get term frequency for this doc\n",
    "                        lexicon[token][1] += 1  # increment document frequency (df)\n",
    "                        lexicon[token][2] += tf  # increment total term frequency (tf)\n",
    "\n",
    "                    doclen = len(tokens)\n",
    "                    doc_index.append((str(doc_id), doclen))\n",
    "                    total_dl += doclen\n",
    "                    num_docs += 1                    \n",
    "                    pbar.update(1)\n",
    "                    \n",
    "     # Calculate average document length (avdl)\n",
    "    avdl = total_dl / num_docs if num_docs > 0 else 0\n",
    "                    \n",
    "    stats = {\n",
    "        'num_docs': num_docs,\n",
    "        'num_terms': len(lexicon),\n",
    "        'num_tokens': total_dl,\n",
    "        'avdl': avdl  # Add avdl to stats\n",
    "    }\n",
    "    return lexicon, {'docids': inv_d, 'freqs': inv_f}, doc_index, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:39.982267Z",
     "start_time": "2024-11-19T17:27:39.948216Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import bisect\n",
    "\n",
    "\n",
    "class InvertedIndex:\n",
    "\n",
    "    class PostingListIterator:\n",
    "        def __init__(self, docids, freqs, doc, avdl):\n",
    "            self.docids = docids\n",
    "            self.freqs = freqs\n",
    "            self.pos = 0\n",
    "            self.doc = doc\n",
    "            self.total_docs_number = len(doc)\n",
    "            self.avdl = avdl\n",
    "\n",
    "        def docid(self):\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            return self.docids[self.pos]\n",
    "\n",
    "\n",
    "        ###################################################################################        \n",
    "        def score(self): # TODO : check if correct, this is TF-IDF score\n",
    "            \"\"\"\n",
    "            Calculate TF-IDF score of the current document in the posting list.\n",
    "            \"\"\"\n",
    "            if self.is_end_list():\n",
    "                return math.inf \n",
    "            \n",
    "            tf = self.freqs[self.pos]\n",
    "                        \n",
    "            if tf > 0:\n",
    "                wtd = 1 + math.log(tf)\n",
    "            else:\n",
    "                wtd = 0 # avoid log(0)\n",
    "            \n",
    "            df = self.len()  # document frequency\n",
    "            if df > 0:\n",
    "                idf = math.log(self.total_docs_number / df)\n",
    "            else:\n",
    "                idf = 0  # avoid log(0)\n",
    "            \n",
    "            # finally calculate tf-idf score\n",
    "            tfidf = wtd * idf\n",
    "\n",
    "            return tfidf\n",
    "\n",
    "        ###################################################################################\n",
    "        # new score_bm25 function\n",
    "        # TODO: check if correct\n",
    "        def score_bm25(self): # Modified to match the BM25 formula from the slides\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            else:\n",
    "                # Standard BM25 parameters\n",
    "                b = 0.75\n",
    "                k_1 = 1.5\n",
    "                \n",
    "                # Length of the current document\n",
    "                dl = self.doc[self.docid()][1]\n",
    "                \n",
    "                # Term frequency in the current document\n",
    "                tf = self.freqs[self.pos]\n",
    "                \n",
    "                # Total number of documents in the collection\n",
    "                N = self.total_docs_number\n",
    "                \n",
    "                # Number of documents containing the term\n",
    "                n = self.len()  # document frequency\n",
    "                \n",
    "                # Calculate document length normalization component (B_j)\n",
    "                B_j = (1 - b) + b * (dl / self.avdl)\n",
    "                \n",
    "                # Calculate the IDF component\n",
    "                idf = math.log( N / n)\n",
    "                \n",
    "                # Calculate the BM25 score\n",
    "                rsv_bm25 = ((tf) / (tf + k_1 * B_j)) * idf\n",
    "                \n",
    "                return rsv_bm25\n",
    "            \n",
    "            ###################################################################################\n",
    "\n",
    "        def next(self, target=None):\n",
    "            if not target:\n",
    "                if not self.is_end_list():\n",
    "                    self.pos += 1\n",
    "            else:\n",
    "                if target > self.docid():\n",
    "                    self.pos = bisect.bisect_left(self.docids, target, self.pos)\n",
    "\n",
    "        def is_end_list(self):\n",
    "            return self.pos == len(self.docids)\n",
    "\n",
    "\n",
    "        def len(self):\n",
    "            return len(self.docids)\n",
    "        \n",
    "\n",
    "    def __init__(self, lex, inv, doc, stats):\n",
    "        self.lexicon = lex\n",
    "        self.inv = inv\n",
    "        self.doc = doc\n",
    "        self.stats = stats\n",
    "\n",
    "    def num_docs(self):\n",
    "        return self.stats['num_docs']\n",
    "    \n",
    "    def avdl(self):\n",
    "        return self.stats['avdl']\n",
    "\n",
    "    def get_posting(self, termid):\n",
    "        return InvertedIndex.PostingListIterator(self.inv['docids'][termid], self.inv['freqs'][termid], self.doc, self.stats['avdl'])\n",
    "    \n",
    "    def get_termids(self, tokens):\n",
    "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
    "\n",
    "    def get_postings(self, termids):\n",
    "        return [self.get_posting(termid) for termid in termids]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:40.060261Z",
     "start_time": "2024-11-19T17:27:40.033105Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO remove\n",
    "# import cProfile\n",
    "# import pstats\n",
    "\n",
    "# cProfile.run(\"build_index('./vaswani.tsv')\", \"output.prof\")\n",
    "# p = pstats.Stats(\"output.prof\")\n",
    "# p.sort_stats(\"cumtime\").print_stats(10)\n",
    "# os.remove(\"output.prof\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the index on the chosen collection \n",
    "\n",
    "Now build up the index for the chosen collection. It is built only if a pickled version of its components doesn't exist already :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.514455Z",
     "start_time": "2024-11-19T17:27:40.142154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di documenti: 8841823\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# If the 'pickles' directory does not exist, we first create it\n",
    "os.makedirs('./pickles', exist_ok=True)\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "    try: # try to open the pickled files, else build the index\n",
    "        with open('./pickles/inv_index.pkl', 'rb') as f:\n",
    "            inv_index = pickle.load(f)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        lex, inv, doc, stats = build_index('./collection/'+chosen_collection + '/'+chosen_collection+'.tsv')\n",
    "\n",
    "        # Save the lexicon, inverted lists, and document index to disk\n",
    "        with open('./pickles/lex.pkl', 'wb') as f:\n",
    "            pickle.dump(lex, f)\n",
    "        with open('./pickles/inv.pkl', 'wb') as f:\n",
    "            pickle.dump(inv, f)\n",
    "        with open('./pickles/doc.pkl', 'wb') as f:\n",
    "            pickle.dump(doc, f)\n",
    "        with open('./pickles/stats.pkl', 'wb') as f:\n",
    "            pickle.dump(stats, f)\n",
    "                    \n",
    "        # Compress the inverted lists\n",
    "        #inv['docids'], inv['freqs'] = compress_index(lex, inv['docids'], inv['freqs'])\n",
    "        \n",
    "        inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "        with open('./pickles/inv_index.pkl', 'wb') as f:\n",
    "            pickle.dump(inv_index, f)\n",
    "else:\n",
    "    lex, inv, doc, stats = build_index('./collection/'+chosen_collection + '/'+chosen_collection+'.tsv')\n",
    "    inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "\n",
    "\n",
    "print(f\"Numero di documenti: {inv_index.num_docs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.577071Z",
     "start_time": "2024-11-19T17:27:41.566029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avdl: 34.687022122021666\n"
     ]
    }
   ],
   "source": [
    "# print avdl\n",
    "print(f\"Avdl: {inv_index.avdl()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.654971Z",
     "start_time": "2024-11-19T17:27:41.635929Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO remove\n",
    "# # Create a test collection\n",
    "# test_collection = [\n",
    "#     \"0\\tterm1 term2 term3\",\n",
    "#     \"1\\tterm2 term3 term4\",\n",
    "#     \"2\\tterm1 term4 term5\",\n",
    "#     \"3\\tterm3 term5 term6\",\n",
    "#     \"4\\tterm1 term2 term3\",\n",
    "# ]\n",
    "\n",
    "# # Write the fake collection to a temporary file\n",
    "# with open('./collection/test_collection.tsv', 'w') as f:\n",
    "#     for line in test_collection:\n",
    "#         f.write(line + '\\n')\n",
    "\n",
    "# # Call the build_index function on the test collection\n",
    "# lex, inv, doc, stats = build_index('./collection/test_collection.tsv')\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Lexicon:\", lex)\n",
    "# print(\"Inverted Index (docids):\", inv['docids'])\n",
    "# print(\"Inverted Index (freqs):\", inv['freqs'])\n",
    "# print(\"Document Index:\", doc)\n",
    "# print(\"Statistics:\", stats)\n",
    "\n",
    "# inv_index = InvertedIndex(lex, inv, doc, stats)\n",
    "\n",
    "# query = \"term1 term2\"\n",
    "# termids = inv_index.get_termids(query.split())\n",
    "# postings = inv_index.get_postings(termids)\n",
    "# print(f\"Query: '{query}', TermID: {termids}\")\n",
    "# for posting in postings:\n",
    "#     while not posting.is_end_list():\n",
    "#         print(f\"docid: {posting.docid()}, score: {posting.score_bm25()}\")\n",
    "#         posting.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.718244Z",
     "start_time": "2024-11-19T17:27:41.709662Z"
    }
   },
   "outputs": [],
   "source": [
    "#print_pickled_size('inv_index', inv_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download and prepare queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.796711Z",
     "start_time": "2024-11-19T17:27:41.768982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  200\n",
      "Number of relevance judgments:  9260\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "if chosen_collection not in [\"vaswani\", \"msmarco\"]:\n",
    "    raise ValueError(\"chosen_collection must be one of ['vaswani', 'msmarco']\")\n",
    "\n",
    "if chosen_collection == \"msmarco\":\n",
    "    if not os.path.exists('./collection/msmarco/msmarco-queries.tsv'):\n",
    "        url = 'https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz'\n",
    "        gdown.download(url, './collection/msmarco/msmarco-test2019-queries.tsv.gz', quiet=False)\n",
    "        with gzip.open('./collection/msmarco/msmarco-test2019-queries.tsv.gz', 'rt') as f_in:\n",
    "            with open('./collection/msmarco/msmarco-queries.tsv', 'w') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "        os.remove('./collection/msmarco/msmarco-test2019-queries.tsv.gz') # delete the compressed file\n",
    "    queries = pd.read_csv('./collection/msmarco/msmarco-queries.tsv', sep='\\t', header=None)\n",
    "    queries.columns = ['qid', 'query']\n",
    "    print(\"Number of queries: \",len(queries))\n",
    "\n",
    "    if not os.path.exists('./collection/msmarco/msmarco-qrels.txt'):\n",
    "        url = 'https://trec.nist.gov/data/deep/2019qrels-pass.txt'\n",
    "        gdown.download(url, './collection/msmarco/msmarco-qrels.txt', quiet=False)\n",
    "    qrels = pd.read_csv('./collection/msmarco/msmarco-qrels.txt', sep=' ', header=None)\n",
    "    qrels.columns = ['qid', 'Q0', 'docid', 'rating']\n",
    "    print(\"Number of relevance judgments: \",len(qrels))\n",
    "\n",
    "\n",
    "elif chosen_collection == \"vaswani\":\n",
    "    queries = pd.DataFrame(vaswani_dataset.queries_iter())\n",
    "    queries.columns = ['qid', 'query']\n",
    "    print(\"Number of queries: \",len(list(vaswani_dataset.queries_iter()))) \n",
    "    if not os.path.exists('./collection/vaswani/vaswani-queries.tsv'):\n",
    "        queries.to_csv('./collection/vaswani/vaswani-queries.tsv', sep='\\t', header=False, index=False)\n",
    "    qrels = pd.DataFrame(vaswani_dataset.qrels_iter()) \n",
    "    qrels.columns = ['qid', 'docid', 'relevance', 'iteration']\n",
    "    qrels['docid'] = (qrels['docid'].astype(int) - 1).astype(str) # convert to 0-based indexing\n",
    "\n",
    "    if not os.path.exists('./collection/vaswani/vaswani-qrels.txt'):\n",
    "        qrels.to_csv('./collection/vaswani/vaswani-qrels.txt', sep='\\t', header=False, index=False)\n",
    "    print(\"Number of relevance judgments: \",len(list(vaswani_dataset.qrels_iter())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.859156Z",
     "start_time": "2024-11-19T17:27:41.848111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of queries is:  200\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class QueriesDataset:\n",
    "    def __init__(self, df):\n",
    "        self.queries = [Query(row.query_id, row.text) for row in df.itertuples()]\n",
    "\n",
    "    def queries_iter(self):\n",
    "        return iter(self.queries)\n",
    "\n",
    "    def queries_count(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def get_query(self, query_id):\n",
    "        return self.queries[query_id]\n",
    "\n",
    "\n",
    "Query = namedtuple('Query', ['query_id', 'text'])\n",
    "queries.columns = ['query_id', 'text']\n",
    "queries_dataset = QueriesDataset(queries)\n",
    "print(\"The number of queries is: \", queries_dataset.queries_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the functions necessary to perform TAAT and DAAT query processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need a TopQueue class, which stores the top  K  (score, docid) tuples, using an heap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:41.954190Z",
     "start_time": "2024-11-19T17:27:41.931158Z"
    }
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class TopQueue:\n",
    "    def __init__(self, k=10, threshold=0.0):\n",
    "        self.queue = []\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.queue)\n",
    "\n",
    "    def would_enter(self, score):\n",
    "        return score > self.threshold\n",
    "\n",
    "    def clear(self, new_threshold=None):\n",
    "        self.queue = []\n",
    "        if new_threshold:\n",
    "            self.threshold = new_threshold\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<{self.size()} items, th={self.threshold} {self.queue}'\n",
    "\n",
    "    def insert(self, docid, score):\n",
    "        if score > self.threshold:\n",
    "            if self.size() >= self.k:\n",
    "                heapq.heapreplace(self.queue, (score, docid))\n",
    "            else:\n",
    "                heapq.heappush(self.queue, (score, docid))\n",
    "            if self.size() >= self.k:\n",
    "                self.threshold = max(self.threshold, self.queue[0][0])\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "#print(sorted(topq.queue, reverse=True)) # print the queue sorted by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:42.016394Z",
     "start_time": "2024-11-19T17:27:42.004032Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def taat(postings, k=10):\n",
    "    A = defaultdict(float)\n",
    "    for posting in postings:\n",
    "        current_docid = posting.docid()\n",
    "        while current_docid != math.inf:\n",
    "            A[current_docid] += posting.score()\n",
    "            posting.next()\n",
    "            current_docid = posting.docid()\n",
    "    top = TopQueue(k)\n",
    "    for docid, score in A.items():\n",
    "        top.insert(docid, score)\n",
    "    return sorted(top.queue, reverse=True)\n",
    "\n",
    "\n",
    "def query_process(query, index):\n",
    "    qtokens = set(preprocess(query))\n",
    "    qtermids = index.get_termids(qtokens)\n",
    "    postings = index.get_postings(qtermids)\n",
    "    return taat(postings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:42.080146Z",
     "start_time": "2024-11-19T17:27:42.068274Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def min_docid(postings):\n",
    "    min_docid = math.inf\n",
    "    for p in postings:\n",
    "        if not p.is_end_list():\n",
    "            min_docid = min(p.docid(), min_docid)\n",
    "    return min_docid\n",
    "\n",
    "def daat(postings, k=10):\n",
    "    top = TopQueue(k)\n",
    "    current_docid = min_docid(postings)\n",
    "    while current_docid != math.inf:\n",
    "        score = 0\n",
    "        next_docid = math.inf\n",
    "        for posting in postings:\n",
    "            if posting.docid() == current_docid:\n",
    "                score += posting.score()\n",
    "                posting.next()\n",
    "            if not posting.is_end_list():\n",
    "                next_docid = posting.docid()\n",
    "        top.insert(current_docid, score)\n",
    "        current_docid = next_docid\n",
    "    return sorted(top.queue, reverse=True)\n",
    "\n",
    "def query_process(query, index):\n",
    "    qtokens = set(preprocess(query))\n",
    "    qtermids = index.get_termids(qtokens)\n",
    "    postings = index.get_postings(qtermids)\n",
    "    return daat(postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:42.158183Z",
     "start_time": "2024-11-19T17:27:42.146647Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "@profile\n",
    "def query_processing(queries_iter, fn):\n",
    "    #for q in tqdm(queries_iter, desc=\"Processing queries\", total=queries_dataset.queries_count(), unit=\"query\"):\n",
    "    for q in queries_iter:\n",
    "        query = preprocess(q.text)\n",
    "        termids = inv_index.get_termids(query)\n",
    "        postings = inv_index.get_postings(termids)\n",
    "        res = fn(postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:42.268199Z",
     "start_time": "2024-11-19T17:27:42.255565Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# import pstats\n",
    "\n",
    "# cProfile.run(\"query_processing(queries_dataset.queries_iter(), taat)\", \"./perfm/result.prof\")\n",
    "# p = pstats.Stats(\"./perfm/result.prof\")\n",
    "# p.sort_stats(\"cumtime\").print_stats(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:43.705732Z",
     "start_time": "2024-11-19T17:27:42.309256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_processing (285906.451 ms)\n"
     ]
    }
   ],
   "source": [
    "#query_processing(queries_dataset.queries_iter(), taat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:48.351530Z",
     "start_time": "2024-11-19T17:27:43.756372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_processing (614704.556 ms)\n"
     ]
    }
   ],
   "source": [
    "#query_processing(queries_dataset.queries_iter(), daat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relevance assessment (called ***qrel*** in `ir_datasets`) is composed by:\n",
    "* a **topic id** (called *query_id* in `ir_datasets`) as in a topic,\n",
    "* a **docno** (called *doc_id* in `ir_datasets`) as in a document,\n",
    "* a **judgement** (called *relevance* in `ir_datasets`) as a binary or graded relevance judgment/label, and\n",
    "* an **iteration**, **UNUSED** and always equal to the string `'0'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:48.428545Z",
     "start_time": "2024-11-19T17:27:48.400834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevance judgments:  9260\n"
     ]
    }
   ],
   "source": [
    "# get the qrels for the chosen collection\n",
    "# as above but space separated\n",
    "'''qrels = pd.read_csv('./collection/'+chosen_collection+'/'+chosen_collection+'-qrels.txt', sep=' ', header=None)\n",
    "qrels.columns = ['query_id', 'doc_id', 'relevance', 'iteration']\n",
    "print(\"Number of relevance judgments: \",len(qrels))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:48.522665Z",
     "start_time": "2024-11-19T17:27:48.509131Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_run_file(queries_iter, fn, run_id, output_file):\n",
    "    \"\"\"\n",
    "    Preprocess the queries and write the results to a run file.\n",
    "    :param queries_iter: Query iterator\n",
    "    :param fn: Function to process the postings and return the results in the format (score, docid)\n",
    "    :param run_id: Name identifier for the run\n",
    "    :param output_file: Output run file\n",
    "    \"\"\"\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "    with open(f\"./results/{output_file}\", \"w\") as f:\n",
    "        for q in queries_iter:\n",
    "            topic_id = q.query_id \n",
    "            query = preprocess(q.text)\n",
    "            termids = inv_index.get_termids(query)\n",
    "            postings = inv_index.get_postings(termids)\n",
    "            results = fn(postings, k=100)\n",
    "            \n",
    "            if results:\n",
    "                # Write results to the run file\n",
    "                for rank, (score, docno) in enumerate(results, start=1):\n",
    "                    line = f\"{topic_id}\\tQ0\\t{docno}\\t{rank}\\t{score:.6f}\\t{run_id}\\n\"\n",
    "                    f.write(line)\n",
    "            else:\n",
    "                # Annotate that no results were found for this query\n",
    "                line = f\"{topic_id}\\tQ0\\tNO_RESULTS\\t0\\t0.0\\t{run_id}\\n\"\n",
    "                f.write(line)\n",
    "\n",
    "    print(f\"Run file {output_file} produced successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:49.927949Z",
     "start_time": "2024-11-19T17:27:48.573038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run file msmarco.run produced successfully.\n"
     ]
    }
   ],
   "source": [
    "#create_run_file(queries_dataset.queries_iter(), taat, \"run\", f\"{chosen_collection}.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841823\n"
     ]
    }
   ],
   "source": [
    "print(inv_index.num_docs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:50.675517Z",
     "start_time": "2024-11-19T17:27:50.633093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for t in T:\\n    # print results[t]\\n    # print A[t]\\n    print(results[t])\\n    print(A[t]) \\n\\nprint(f'Topic {t}: F1 = {f1_score(results[t], A[t])}')\\n    \\nfor t in T:\\n    print(f'Topic {t}: P = {precision(results[t], A[t])}')\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gold era sopra, rimosso perchè inutile\n",
    "# TODO remove\n",
    "'''def precision(results, qrels): # i qrels sono i relevance assesment files\n",
    "    retrieved = len(results)\n",
    "    retrieved_relevant = sum([qrels[d] for d in results])\n",
    "    return retrieved_relevant/retrieved # effettivamente torna\n",
    "\n",
    "def recall(results, qrels):\n",
    "    relevant = sum(qrels)\n",
    "    retrieved_relevant = sum([qrels[d] for d in results])\n",
    "    return retrieved_relevant/relevant\n",
    "\n",
    "def f1_score(results, qrels):\n",
    "    P = precision(results, qrels)\n",
    "    R = recall(results, qrels)\n",
    "    return 2*R*P/(R+P)\n",
    "    ''''''# TODO : rimuovi perchè non esiste che sia zero\n",
    "    if P + R == 0:\n",
    "        return 0'''\n",
    "    \n",
    "    \n",
    "'''for t in T:\n",
    "    # print results[t]\n",
    "    # print A[t]\n",
    "    print(results[t])\n",
    "    print(A[t]) \n",
    "\n",
    "print(f'Topic {t}: F1 = {f1_score(results[t], A[t])}')\n",
    "    \n",
    "for t in T:\n",
    "    print(f'Topic {t}: P = {precision(results[t], A[t])}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:50.863772Z",
     "start_time": "2024-11-19T17:27:50.786679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import numpy as np\\n\\ndef precision_at_k(results, qrels, k):\\n    return precision(results[:k], qrels) # prende i primi k risultati e calcola la precisione su questi\\n\\nfor k in [1, 3, 5, 10, 20]:\\n    print(f'P@{k} = {np.mean([precision_at_k(results[t], A[t], k) for t in T])}') # media delle precisioni per ogni topic\\n\\n\\ndef recall_at_k(results, qrels, k):\\n    return recall(results[:k], qrels)\\n\\nfor k in [1, 3, 5, 10, 20]:\\n    print(f'R@{k} = {np.mean([recall_at_k(results[t], A[t], k) for t in T])}') # stessa cosa di prima ma per recall\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "\n",
    "def precision_at_k(results, qrels, k):\n",
    "    return precision(results[:k], qrels) # prende i primi k risultati e calcola la precisione su questi\n",
    "\n",
    "for k in [1, 3, 5, 10, 20]:\n",
    "    print(f'P@{k} = {np.mean([precision_at_k(results[t], A[t], k) for t in T])}') # media delle precisioni per ogni topic\n",
    "\n",
    "\n",
    "def recall_at_k(results, qrels, k):\n",
    "    return recall(results[:k], qrels)\n",
    "\n",
    "for k in [1, 3, 5, 10, 20]:\n",
    "    print(f'R@{k} = {np.mean([recall_at_k(results[t], A[t], k) for t in T])}') # stessa cosa di prima ma per recall'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "from ir_measures import *\n",
    "\n",
    "chosen_collection = \"msmarco\"\n",
    "\n",
    "# Load the qrels\n",
    "qrels = pd.read_csv('./collection/'+chosen_collection+'/'+chosen_collection+'-qrels.txt', sep=' ', header=None)\n",
    "qrels.columns = ['query_id', 'Q0', 'doc_id', 'relevance']\n",
    "qrels['query_id'] = qrels['query_id'].apply(str)\n",
    "qrels['doc_id'] = qrels['doc_id'].apply(str)\n",
    "qrels['relevance'] = qrels['relevance'].apply(int)\n",
    "# Load the run\n",
    "run_file = list(ir_measures.read_trec_run(f'./results/{chosen_collection}.run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{SetP: 0.26418604651162786}\n",
      "{SetR: 0.34199089792047155}\n"
     ]
    }
   ],
   "source": [
    "# The Set Precision (SetP); i.e., the number of relevant docs divided by the total number retrieved\n",
    "print(ir_measures.calc_aggregate([SetP], qrels, run_file))\n",
    "\n",
    "# The Set Recall (SetR); i.e., the number of relevant docs divided by the total number of relevant documents\n",
    "print(ir_measures.calc_aggregate([SetR], qrels, run_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P@5: 0.5581395348837209}\n",
      "{P@5: 0.5581395348837209}\n",
      "{P(rel=2)@5: 0.39534883720930225}\n",
      "{P(rel=3)@5: 0.17209302325581394}\n",
      "{P@5: 0.5581395348837209}\n",
      "{P(rel=2,judged_only=True)@5: 0.4372093023255814}\n",
      "{P(rel=3,judged_only=True)@5: 0.19069767441860466}\n"
     ]
    }
   ],
   "source": [
    "# PRECISION at k\n",
    "\n",
    "print(ir_measures.calc_aggregate([P@5], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([P(rel=1)@5], qrels, run_file))\t# default is rel=1\n",
    "print(ir_measures.calc_aggregate([P(rel=2)@5], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([P(rel=3)@5], qrels, run_file))\n",
    "\n",
    "print(ir_measures.calc_aggregate([P(rel=1, judged_only=True)@5], qrels, run_file))\t# default is judged_only=False\n",
    "print(ir_measures.calc_aggregate([P(rel=2, judged_only=True)@5], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([P(rel=3, judged_only=True)@5], qrels, run_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{R@100: 0.34199089792047155}\n",
      "{R@5: 0.06886452820043387}\n",
      "{R(rel=2)@5: 0.09394562802992476}\n",
      "{R(rel=3)@5: 0.09221170124734597}\n",
      "{R(judged_only=True)@5: 0.0747698051731351}\n",
      "{R(rel=2,judged_only=True)@5: 0.09949099373829699}\n",
      "{R(rel=3,judged_only=True)@5: 0.09811780399852398}\n"
     ]
    }
   ],
   "source": [
    "# RECALL at k\n",
    "\n",
    "print(ir_measures.calc_aggregate([R@100], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([R(rel=1)@5], qrels, run_file))\t# default is rel=1\n",
    "print(ir_measures.calc_aggregate([R(rel=2)@5], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([R(rel=3)@5], qrels, run_file))\n",
    "\n",
    "print(ir_measures.calc_aggregate([R(rel=1, judged_only=True)@5], qrels, run_file))\t# default is judged_only=False\n",
    "print(ir_measures.calc_aggregate([R(rel=2, judged_only=True)@5], qrels, run_file))\n",
    "print(ir_measures.calc_aggregate([R(rel=3, judged_only=True)@5], qrels, run_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{P(rel=2)@5: 0.39534883720930225, AP(rel=2): 0.1855357022003192, Judged@10: 0.7581395348837208, Bpref: 0.28740518536791293, AP: 0.20267250123025782, P@5: 0.5581395348837209, nDCG@10: 0.41352178810945667, Bpref(rel=2): 0.2345261473754138}\n"
     ]
    }
   ],
   "source": [
    "print(ir_measures.calc_aggregate([P@5, P(rel=2)@5, nDCG@10, AP, AP(rel=2), Bpref, Bpref(rel=2), Judged@10], qrels, run_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:51.114391Z",
     "start_time": "2024-11-19T17:27:51.039101Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : da rivedere\n",
    "\n",
    "count = 0\n",
    "for metric in ir_measures.iter_calc([P@5, P(rel=2)@5, nDCG@10, AP, AP(rel=2), Bpref, Bpref(rel=2), Judged@10], qrels, run_file):\n",
    "  print(metric)\n",
    "  count += 1\n",
    "  if count >= 10: break # only show top 10 items\n",
    "\n",
    "run_file_p_rel2_5 = {m.query_id: m.value for m in ir_measures.iter_calc([Bpref(rel=2)], qrels, run_file)}\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "qids = list(run_file_p_rel2_5.keys())\n",
    "#ttest_rel([run_file_p_rel2_5[v] for v in qids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:27:51.223580Z",
     "start_time": "2024-11-19T17:27:51.165387Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "# UI elements\n",
    "search_bar = widgets.Text(\n",
    "    placeholder='Type in a query...',\n",
    "    description='Search:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    button_style='success',\n",
    "    tooltip='Execute the query',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "score_function_rbtn = widgets.RadioButtons(options=['TF-IDF', 'BM25'], description='Scoring function:', disabled=False)\n",
    "algo_rbtn = widgets.RadioButtons(options=['TAAT', 'DAAT'], description='Algorithm:', disabled=False)\n",
    "_style = widgets.HTML(\n",
    "    \"<style>.widget-radio-box {flex-direction: row !important;}.widget-radio-box\"\n",
    "    \" label{margin:2px !important;width: 100px !important;}</style>\",\n",
    "    layout=widgets.Layout(display=\"none\"),\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "\n",
    "def on_search_click(b):\n",
    "    with output_area:\n",
    "        clear_output()  # clean previous output\n",
    "        query = search_bar.value\n",
    "        if not query.strip():\n",
    "            print(\"Please, type in a query.\")\n",
    "            return\n",
    "        \n",
    "        selected_scoring_function = score_function_rbtn.value\n",
    "        print(f\"Selected scoring function: {selected_scoring_function}\")\n",
    "        # TODO : implement the selected scoring function\n",
    "\n",
    "        selected_algorithm = algo_rbtn.value\n",
    "        print(f\"Selected Algorithm: {selected_algorithm}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # --- QUERY EXECUTION ---\n",
    "        processed_query = preprocess(query)\n",
    "        termids = inv_index.get_termids(processed_query)\n",
    "        postings = inv_index.get_postings(termids)\n",
    "        \n",
    "        if selected_algorithm == 'TAAT':\n",
    "            results = taat(postings)\n",
    "        else:\n",
    "            results = daat(postings)\n",
    "        # ------------------------\n",
    "        elapsed_time = (time.time() - start_time) * 1000 # convert in ms\n",
    "\n",
    "        # finally show the results\n",
    "        print(f\"Found: {len(results)} documents\\n\")\n",
    "        for res in results:\n",
    "            res = (round(res[0], 4), res[1]) # TODO : si potrebbe spostare direttamente nella score function\n",
    "            print(f\" - {res}\")\n",
    "        print(f\"\\nExecution time: {elapsed_time:.2f} ms\")\n",
    "\n",
    "search_button.on_click(on_search_click)\n",
    "# link search button to the enter key\n",
    "search_bar.continuous_update = False\n",
    "search_bar.observe(on_search_click, names='value')\n",
    "\n",
    "top_row = widgets.HBox([score_function_rbtn,_style])\n",
    "middle_row = widgets.HBox([algo_rbtn,_style])\n",
    "bottom_row = widgets.HBox([search_bar, search_button])\n",
    "\n",
    "# finally display the UI\n",
    "display(widgets.VBox([top_row,middle_row, bottom_row]))\n",
    "display(output_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTerrier and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:00:25.080832Z",
     "start_time": "2024-11-19T18:00:16.846453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.10 (build: craigm 2024-08-22 17:33), helper_version=0.0.8]\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "\n",
    "# note that pt.started() and pt.init() are deprecated\n",
    "\n",
    "if not pt.java.started():\n",
    "    pt.java.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T18:31:51.495278Z",
     "start_time": "2024-11-19T18:31:51.383429Z"
    }
   },
   "outputs": [],
   "source": [
    "'''# Load the pickled inverted index\n",
    "df = pd.read_csv(\"collection/vaswani/vaswani.tsv\", sep=\"\\t\")\n",
    "\n",
    "# assign columns\n",
    "df.columns = [\"docno\", \"text\"]\n",
    "\n",
    "# Convert columns to strings\n",
    "df[\"docno\"] = df[\"docno\"].astype(str)\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(df.head())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T16:12:33.562549Z",
     "start_time": "2024-11-20T16:12:30.199027Z"
    }
   },
   "outputs": [],
   "source": [
    "'''indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)\n",
    "#indexer = pt.IterDictIndexer(\"./index_3docs\")\n",
    "indexref = indexer.index(df[\"text\"], df[\"docno\"])\n",
    "indexref.toString()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841822\n",
      "Number of terms: 1170682\n",
      "Number of postings: 215238431\n",
      "Number of fields: 1\n",
      "Number of tokens: 288759502\n",
      "Field names: [text]\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexref = pt.IndexRef.of(os.path.abspath(\"index_3docs/data.properties\"))\n",
    "index = pt.IndexFactory.of(indexref)\n",
    "print(index.getCollectionStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "# File path for the input file\n",
    "file_path = \"collection/msmarco/msmarco-queries.tsv\"  # Replace with your file path\n",
    "# Read the input file\n",
    "queries = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"qid\", \"query\"])\n",
    "\n",
    "# Apply preprocessing to each query\n",
    "queries[\"processed_query\"] = queries[\"query\"].apply(preprocess)\n",
    "\n",
    "# Save the processed queries to a new file\n",
    "output_path = \"processed_queries.txt\"\n",
    "queries[[\"qid\", \"processed_query\"]].to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Read the processed file with the correct column names\n",
    "processed_queries = pd.read_csv(output_path, sep=\"\\t\", names=[\"qid\", \"query\"], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processato salvato in: final_processed_queries.txt\n",
      "       qid                  query\n",
      "0  1108939        slow flow blood\n",
      "1  1112389  counti grand rapid mn\n",
      "2   792752                 ruclip\n",
      "3  1119729           noseble nose\n",
      "4  1105095  sugar lake lodg locat\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def concatenate_list(query):\n",
    "    \"\"\"\n",
    "    Funzione per concatenare gli elementi di una lista di termini in una stringa.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_list = ast.literal_eval(query)  # Converte la stringa in lista\n",
    "        return \" \".join(query_list)  # Concatena gli elementi della lista con uno spazio\n",
    "    except (ValueError, SyntaxError):\n",
    "        return query  # Restituisci il valore originale se non è una lista valida\n",
    "\n",
    "\n",
    "# Step 1: Leggi il file delle query originali\n",
    "file_path = \"collection/msmarco/msmarco-queries.tsv\"  # Sostituisci con il percorso del file\n",
    "queries = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"qid\", \"query\"])\n",
    "\n",
    "# Step 2: Applica la funzione preprocess a tutte le query\n",
    "queries[\"processed_query\"] = queries[\"query\"].apply(preprocess)\n",
    "\n",
    "# Step 3: Salva le query preprocessate in un file temporaneo\n",
    "temp_output_path = \"processed_queries_temp.txt\"\n",
    "queries[[\"qid\", \"processed_query\"]].to_csv(temp_output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Step 4: Rileggi il file temporaneo per applicare concatenate_list\n",
    "processed_queries = pd.read_csv(temp_output_path, sep=\"\\t\")\n",
    "\n",
    "# Applica concatenate_list alla colonna 'processed_query'\n",
    "processed_queries[\"qid\"] = processed_queries[\"qid\"].astype(str)\n",
    "processed_queries[\"query\"] = processed_queries[\"processed_query\"].apply(concatenate_list)\n",
    "processed_queries = processed_queries[[\"qid\", \"query\"]]\n",
    "# Step 5: Salva il file finale con le colonne 'qid' e 'query'\n",
    "final_output_path = \"final_processed_queries.txt\"\n",
    "processed_queries[[\"qid\", \"query\"]].to_csv(final_output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Output per conferma\n",
    "print(f\"File processato salvato in: {final_output_path}\")\n",
    "print(processed_queries.head())\n",
    "\n",
    "processed_queries[\"qid\"] = processed_queries[\"qid\"].astype(str)\n",
    "\n",
    "\n",
    "qrels = pd.read_csv('./collection/'+chosen_collection+'/'+chosen_collection+'-qrels.txt', sep=' ', header=None)\n",
    "qrels.columns = ['qid', 'Q0', 'docno', 'relevance']\n",
    "qrels['qid'] = qrels['qid'].apply(str)\n",
    "qrels['docno'] = qrels['docno'].apply(str)\n",
    "#qrels['relevance'] = qrels['relevance'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di qid in queries: 200\n",
      "Numero totale di qid in qrels: 43\n",
      "Numero di qid comuni: 43\n",
      "Qid mancanti nei qrels: 157\n",
      "Qid mancanti nelle queries: 0\n"
     ]
    }
   ],
   "source": [
    "queries_qids = set(processed_queries[\"qid\"])\n",
    "qrels_qids = set(qrels[\"qid\"])\n",
    "\n",
    "common_qids = queries_qids & qrels_qids\n",
    "missing_in_qrels = queries_qids - qrels_qids\n",
    "missing_in_queries = qrels_qids - queries_qids\n",
    "\n",
    "# Mostra i risultati\n",
    "print(f\"Numero totale di qid in queries: {len(queries_qids)}\")\n",
    "print(f\"Numero totale di qid in qrels: {len(qrels_qids)}\")\n",
    "print(f\"Numero di qid comuni: {len(common_qids)}\")\n",
    "print(f\"Qid mancanti nei qrels: {len(missing_in_qrels)}\")\n",
    "print(f\"Qid mancanti nelle queries: {len(missing_in_queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File salvato in: filtered_msmarco-qrels.txt\n",
      "Numero di valori univoci nella prima colonna ('qid'): 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'queries_qids = set(processed_queries[\"qid\"])\\nqrels_qids = set(qrels[\"qid\"])\\n\\ncommon_qids = queries_qids & qrels_qids\\nmissing_in_qrels = queries_qids - qrels_qids\\nmissing_in_queries = qrels_qids - queries_qids\\n\\n# Mostra i risultati\\nprint(f\"Numero totale di qid in queries: {len(queries_qids)}\")\\nprint(f\"Numero totale di qid in qrels: {len(qrels_qids)}\")\\nprint(f\"Numero di qid comuni: {len(common_qids)}\")\\nprint(f\"Qid mancanti nei qrels: {len(missing_in_qrels)}\")\\nprint(f\"Qid mancanti nelle queries: {len(missing_in_queries)}\")'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Percorso del file da leggere\n",
    "input_file = \"collection/msmarco/msmarco-qrels.txt\"  # Sostituisci con il percorso del tuo file\n",
    "output_file = \"filtered_msmarco-qrels.txt\"  # Nome del file di output\n",
    "\n",
    "# Leggi il file con pandas\n",
    "df = pd.read_csv(input_file, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docno\", \"relevance\"])\n",
    "\n",
    "# Filtra le righe in cui la colonna 'relevance' è diversa da zero\n",
    "filtered_df = df[df[\"relevance\"] != 0]\n",
    "\n",
    "# Salva il risultato in un nuovo file\n",
    "filtered_df.to_csv(output_file, sep=\" \", index=False, header=False)\n",
    "\n",
    "print(f\"File salvato in: {output_file}\")\n",
    "\n",
    "file_path = \"filtered_msmarco-qrels.txt\"\n",
    "\n",
    "# Leggi il file con pandas\n",
    "df = pd.read_csv(file_path, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docno\", \"relevance\"])\n",
    "\n",
    "# Conta il numero di valori univoci nella colonna 'qid'\n",
    "unique_values_count = df[\"qid\"].nunique()\n",
    "\n",
    "# Stampa il numero di valori univoci\n",
    "print(f\"Numero di valori univoci nella prima colonna ('qid'): {unique_values_count}\")\n",
    "\n",
    "\"\"\"queries_qids = set(processed_queries[\"qid\"])\n",
    "qrels_qids = set(qrels[\"qid\"])\n",
    "\n",
    "common_qids = queries_qids & qrels_qids\n",
    "missing_in_qrels = queries_qids - qrels_qids\n",
    "missing_in_queries = qrels_qids - queries_qids\n",
    "\n",
    "# Mostra i risultati\n",
    "print(f\"Numero totale di qid in queries: {len(queries_qids)}\")\n",
    "print(f\"Numero totale di qid in qrels: {len(qrels_qids)}\")\n",
    "print(f\"Numero di qid comuni: {len(common_qids)}\")\n",
    "print(f\"Qid mancanti nei qrels: {len(missing_in_qrels)}\")\n",
    "print(f\"Qid mancanti nelle queries: {len(missing_in_queries)}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di valori univoci nella prima colonna ('qid'): 43\n"
     ]
    }
   ],
   "source": [
    "file_path = \"collection/msmarco/msmarco-qrels.txt\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docno\", \"relevance\"])\n",
    "\n",
    "# Conta il numero di valori univoci nella colonna 'qid'\n",
    "unique_values_count = df[\"qid\"].nunique()\n",
    "\n",
    "# Stampa il numero di valori univoci\n",
    "print(f\"Numero di valori univoci nella prima colonna ('qid'): {unique_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacop\\AppData\\Local\\Temp\\ipykernel_27108\\3385254733.py:2: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  TF_IDF = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
      "C:\\Users\\jacop\\AppData\\Local\\Temp\\ipykernel_27108\\3385254733.py:3: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
      "C:\\Users\\jacop\\AppData\\Local\\Temp\\ipykernel_27108\\3385254733.py:4: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  PL2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>0.370491</td>\n",
       "      <td>0.774485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>0.370611</td>\n",
       "      <td>0.774485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TerrierRetr(PL2)</td>\n",
       "      <td>0.354771</td>\n",
       "      <td>0.769491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name       map  recip_rank\n",
       "0  TerrierRetr(TF_IDF)  0.370491    0.774485\n",
       "1    TerrierRetr(BM25)  0.370611    0.774485\n",
       "2     TerrierRetr(PL2)  0.354771    0.769491"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definizione dei retriever\n",
    "TF_IDF = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "PL2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "\n",
    "# Esegui l'esperimento\n",
    "pt.Experiment(\n",
    "    [TF_IDF, BM25, PL2],\n",
    "    processed_queries,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\", \"recip_rank\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>map reject</th>\n",
       "      <th>map p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.514755</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL2</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name     map  map +  map -  map p-value  map reject  \\\n",
       "0  TF-IDF  0.3705    NaN    NaN          NaN       False   \n",
       "1    BM25  0.3706   15.0   20.0     0.514755       False   \n",
       "2     PL2  0.3548    6.0   35.0     0.000002        True   \n",
       "\n",
       "   map p-value corrected  \n",
       "0                    NaN  \n",
       "1               1.000000  \n",
       "2               0.000004  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [TF_IDF, BM25, PL2],\n",
    "    processed_queries,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\"],\n",
    "    round={\"map\" : 4},\n",
    "    names=['TF-IDF', 'BM25', 'PL2'],\n",
    "    baseline=0,\n",
    "    correction='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacop\\miniconda3\\envs\\mircv\\lib\\site-packages\\pyterrier\\pipelines.py:130: UserWarning: 157 topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.\n",
      "  warn(f'{backfill_count} topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.')\n",
      "c:\\Users\\jacop\\miniconda3\\envs\\mircv\\lib\\site-packages\\pyterrier\\pipelines.py:130: UserWarning: 157 topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.\n",
      "  warn(f'{backfill_count} topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.')\n",
      "c:\\Users\\jacop\\miniconda3\\envs\\mircv\\lib\\site-packages\\pyterrier\\pipelines.py:130: UserWarning: 157 topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.\n",
      "  warn(f'{backfill_count} topic(s) not found in qrels. Scores for these topics are given as NaN and should not contribute to averages.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>1005165</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>100983</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>101169</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>1012021</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>1014126</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>953067</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>962179</td>\n",
       "      <td>map</td>\n",
       "      <td>0.058898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>964223</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>966413</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>TerrierRetr(TF_IDF)</td>\n",
       "      <td>972007</td>\n",
       "      <td>map</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name      qid measure     value\n",
       "360    TerrierRetr(BM25)  1005165     map       NaN\n",
       "288    TerrierRetr(BM25)   100983     map       NaN\n",
       "363    TerrierRetr(BM25)   101169     map       NaN\n",
       "280    TerrierRetr(BM25)  1012021     map       NaN\n",
       "309    TerrierRetr(BM25)  1014126     map       NaN\n",
       "..                   ...      ...     ...       ...\n",
       "162  TerrierRetr(TF_IDF)   953067     map       NaN\n",
       "13   TerrierRetr(TF_IDF)   962179     map  0.058898\n",
       "150  TerrierRetr(TF_IDF)   964223     map       NaN\n",
       "61   TerrierRetr(TF_IDF)   966413     map       NaN\n",
       "156  TerrierRetr(TF_IDF)   972007     map       NaN\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [TF_IDF, BM25, PL2],\n",
    "    processed_queries,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\"],\n",
    "    perquery=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>map reject</th>\n",
       "      <th>map p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.514755</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL2</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name     map  map +  map -  map p-value  map reject  \\\n",
       "0  TF-IDF  0.3705    NaN    NaN          NaN       False   \n",
       "1    BM25  0.3706   15.0   20.0     0.514755       False   \n",
       "2     PL2  0.3548    6.0   35.0     0.000002        True   \n",
       "\n",
       "   map p-value corrected  \n",
       "0                    NaN  \n",
       "1               1.000000  \n",
       "2               0.000004  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [TF_IDF, BM25, PL2],\n",
    "    processed_queries,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\"],\n",
    "    round={\"map\" : 4},\n",
    "    names=['TF-IDF', 'BM25', 'PL2'],\n",
    "    baseline=0,\n",
    "    correction='b',\n",
    "    save_dir='./'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mircv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
