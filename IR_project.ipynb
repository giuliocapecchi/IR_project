{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliocapecchi/IR_project/blob/main/IR_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNk06jLCfXXM",
        "outputId": "07943952-15cf-4a6b-d8a5-a373a7715df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch matplotlib nltk tqdm gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1f7eJ4tFSfq"
      },
      "source": [
        "# 1. Download the collection\n",
        "\n",
        "Con questo modulo si possono scaricare files, quindi ho scaricato la collection e l'ho butttata sul mio drive (ci vogliono circa 30s/1 minuto di tempo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "8oKwHN5yEPTq",
        "collapsed": true,
        "outputId": "99d4c023-de14-406b-93a3-66fc6665972a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_wXJjiwdgc9Kpt7o7atP8oWe-U4Z56hn\n",
            "From (redirected): https://drive.google.com/uc?id=1_wXJjiwdgc9Kpt7o7atP8oWe-U4Z56hn&confirm=t&uuid=d389e6ba-7a60-43ba-8444-500de75e0630\n",
            "To: /content/collection.tsv\n",
            "100%|██████████| 3.06G/3.06G [00:40<00:00, 75.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'collection.tsv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1_wXJjiwdgc9Kpt7o7atP8oWe-U4Z56hn'\n",
        "gdown.download(url, 'collection.tsv', quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mY5w1EETpWSm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "read 'collection.tsv' file and prepare it for data manipulation\n",
        "the file is organized in the following way:\n",
        "<pid>\\t<text>\\n\n",
        "where <pid> is the passage id and <text> is the passage text\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('collection.tsv', sep='\\t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-z1wJvFpXQ_",
        "outputId": "efebd7cb-3545-4c5e-dfee-5c6b92bab3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   doc_id                                               text\n",
            "0       0  The presence of communication amid scientific ...\n",
            "1       1  The Manhattan Project and its atomic bomb help...\n"
          ]
        }
      ],
      "source": [
        "# let's not truncate Pandas output too much\n",
        "pd.set_option('display.max_colwidth', 50) # mettici 150\n",
        "df.columns = ['doc_id', 'text']\n",
        "print(df.head(2)) # returns the first N rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F3wDCYeRpYX5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "def preprocess(s):\n",
        "    # lowercasing\n",
        "    s = s.lower()\n",
        "    # ampersand\n",
        "    s = s.replace(\"&\", \" and \")\n",
        "    # special chars\n",
        "    s = s.translate(dict([(ord(x), ord(y)) for x, y in zip(\"‘’´“”–-\", \"'''\\\"\\\"--\")]))\n",
        "    # acronyms\n",
        "    s = re.sub(r\"\\.(?!(\\S[^. ])|\\d)\", \"\", s) # remove dots that are not part of an acronym\n",
        "    # remove punctuation\n",
        "    s = s.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
        "    # strip whitespaces\n",
        "    s = s.strip()\n",
        "    while \"  \" in s:\n",
        "        s = s.replace(\"  \", \" \")\n",
        "    # tokeniser\n",
        "    s = s.split()\n",
        "    # stopwords\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    s = [t for t in s if t not in stopwords]\n",
        "    # stemming\n",
        "    stemmer = nltk.stem.PorterStemmer().stem\n",
        "    s = [stemmer(t) for t in s]\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vMXjjbwwpZg7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def profile(f):\n",
        "    def f_timer(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = f(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        ms = (end - start) * 1000\n",
        "        print(f\"{f.__name__} ({ms:.3f} ms)\")\n",
        "        return result\n",
        "    return f_timer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def VBEncode(n):\n",
        "    byte = [] # We will store the bytes in a list\n",
        "    while True:\n",
        "        # n % 128 gives us the 7 least significant bits\n",
        "        byte.append(n % 128) # Append 7 bits with most significant bit (control bit) set to 0\n",
        "        if n < 128:\n",
        "            break\n",
        "        n //= 128 # Shift the number to the right by 7 bits\n",
        "\n",
        "    byte[0] += 128 # Set the most significant bit (control bit) set to 1\n",
        "    return byte[::-1] # We provide the resulting list in reverse order\n",
        "\n",
        "\n",
        "def VBEncodeList(n_list):\n",
        "    b = []\n",
        "    for n in n_list:\n",
        "        b.extend(VBEncode(n)) # We extend the list with the bytes of the number\n",
        "    return b\n",
        "\n",
        "\n",
        "def VBDecode(byte_list):\n",
        "    n_list = []\n",
        "    n = 0\n",
        "    for b in byte_list:\n",
        "        if b < 128:\n",
        "            n = 128 * n + b\n",
        "        else:\n",
        "            n = 128 * n + b - 128\n",
        "            n_list.append(n)\n",
        "            n = 0\n",
        "    return n_list\n",
        "\n",
        "\n",
        "print(\"Initial list: [5, 824] -> Encoded list:\", VBEncodeList([5, 824]))\n",
        "print(\"Encoded ist: [133, 6, 184] -> Decoded list:\", VBDecode([133, 6, 184]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmR6-3EBUwA",
        "outputId": "0fe56195-635b-43db-c154-ee8c851ae46d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial list: [5, 824] -> Encoded list: [133, 6, 184]\n",
            "Encoded ist: [133, 6, 184] -> Decoded list: [5, 824]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GEMd0ALMpabE"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "@profile\n",
        "def build_index(dataset):\n",
        "    lexicon = {}\n",
        "    doc_index = []\n",
        "    inv_d, inv_f = {}, {}\n",
        "    termid = 0\n",
        "\n",
        "    num_docs = 0\n",
        "    total_dl = 0\n",
        "    total_toks = 0\n",
        "    for docid, doc in tqdm(enumerate(dataset.docs_iter()), desc='Indexing', total=dataset.docs_count()):\n",
        "        tokens = preprocess(doc.text)\n",
        "        #print(tokens)\n",
        "        token_tf = Counter(tokens)\n",
        "        for token, tf in token_tf.items():\n",
        "            if token not in lexicon:\n",
        "                lexicon[token] = [termid, 0, 0]\n",
        "                inv_d[termid], inv_f[termid] =  [], []\n",
        "                termid += 1\n",
        "            token_id = lexicon[token][0] # prendo il termid\n",
        "            inv_d[token_id].append(docid) # aggiungo il docid alla lista dei docid in cui compare il termine\n",
        "            inv_f[token_id].append(tf) # aggiungo il tf alla lista dei tf in cui compare il termine\n",
        "            lexicon[token][1] += 1 # incremento il df\n",
        "            lexicon[token][2] += tf # tf è quanto compare il termine nel documento\n",
        "        doclen = len(tokens)\n",
        "        doc_index.append((str(doc.doc_id), doclen))\n",
        "        total_dl += doclen\n",
        "        num_docs += 1\n",
        "\n",
        "\n",
        "    stats = {\n",
        "        'num_docs': 1 + docid, # docid parte da 0\n",
        "        'num_terms': len(lexicon),\n",
        "        'num_tokens': total_dl,\n",
        "    }\n",
        "    return lexicon, {'docids': inv_d, 'freqs': inv_f}, doc_index, stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bG1E5wTxpbPq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This class that takes the dataframe we created before with columns 'docno' and 'text', and creates a list of namedtuples\n",
        "\"\"\"\n",
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "class MSMarcoDataset:\n",
        "    def __init__(self, df):\n",
        "        self.docs = [Document(row.doc_id, row.text) for row in df.itertuples()]\n",
        "\n",
        "    def docs_iter(self):\n",
        "        return iter(self.docs)\n",
        "\n",
        "    def docs_count(self):\n",
        "        return len(self.docs)\n",
        "\n",
        "\n",
        "Document = namedtuple('Document', ['doc_id', 'text']) # must define what a document is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "3ec2e40f9cc34efab5544a7727b0686a",
            "b810509205ea45f699bd3848f998a187",
            "78a09b740453455a99e14d6109919c52",
            "17ec15452b0a435bb1d4040d6b8c8b85",
            "292fd00a1b524da2a79f5273768e06d6",
            "e030f29b2cf348d3a2f29aef2a0e5fcb",
            "831e8fd443684346ad096bdd300657d7",
            "8f264f8a61924e879806974dcd2103c8",
            "aba07292495142c4be08ede74d9b7637",
            "2159ab6a19334335ad145938f874bbbb",
            "29ea010f911e48a3b0550a2b21d63345"
          ]
        },
        "id": "Kp2g4Q9VpcYr",
        "outputId": "0ba9f864-f3b2-450d-91b8-49c979e33cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document(doc_id=1, text='A school')\n",
            "Document(doc_id=2, text='Another example.')\n",
            "Document(doc_id=3, text='This is a house.')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Indexing:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ec2e40f9cc34efab5544a7727b0686a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build_index (38.953 ms)\n"
          ]
        }
      ],
      "source": [
        "# Test the MSMarcoDataset class by passing Document(1, \"school\"), Document(2, \"example.\"), Document(3, \"house.\")\n",
        "\n",
        "test_docs = [Document(1, \"A school\"), Document(2, \"Another example.\"), Document(3, \"This is a house.\")]\n",
        "test_dataset = MSMarcoDataset(pd.DataFrame(test_docs, columns=['doc_id', 'text']))\n",
        "\n",
        "for doc in test_dataset.docs_iter():\n",
        "    print(doc)\n",
        "\n",
        "lex, inv, doc, stats = build_index(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlrZVKx3pdM6",
        "outputId": "2b19430b-fe35-418a-c6ce-1d249e89c009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'school': [0, 1, 1], 'anoth': [1, 1, 1], 'exampl': [2, 1, 1], 'hous': [3, 1, 1]}\n",
            "{'docids': {0: [128], 1: [129], 2: [129], 3: [130]}, 'freqs': {0: [129], 1: [129], 2: [129], 3: [129]}}\n",
            "[('1', 1), ('2', 2), ('3', 1)]\n",
            "{'num_docs': 3, 'num_terms': 4, 'num_tokens': 4}\n"
          ]
        }
      ],
      "source": [
        "print(lex)\n",
        "print(inv)\n",
        "print(doc)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ceced8dd-3e3b-4b72-a0b7-2d6d5a2c2a19"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class InvertedIndex:\n",
        "\n",
        "    class PostingListIterator:\n",
        "        def __init__(self, docids, freqs, doc):\n",
        "            self.docids = docids\n",
        "            self.freqs = freqs\n",
        "            self.pos = 0\n",
        "            self.doc = doc\n",
        "\n",
        "        def docid(self):\n",
        "            if self.is_end_list():\n",
        "                return math.inf\n",
        "            return self.docids[self.pos]\n",
        "\n",
        "        def score(self):\n",
        "            if self.is_end_list():\n",
        "                return math.inf\n",
        "            return self.freqs[self.pos]/self.doc[self.docid()][1]\n",
        "\n",
        "        def next(self, target = None):\n",
        "            if not target:\n",
        "                if not self.is_end_list():\n",
        "                    self.pos += 1\n",
        "            else:\n",
        "                if target > self.docid():\n",
        "                    try:\n",
        "                        self.pos = self.docids.index(target, self.pos)\n",
        "                    except ValueError:\n",
        "                        self.pos = len(self.docids)\n",
        "\n",
        "        def is_end_list(self):\n",
        "            return self.pos == len(self.docids)\n",
        "\n",
        "\n",
        "        def len(self):\n",
        "            return len(self.docids)\n",
        "\n",
        "\n",
        "    def __init__(self, lex, inv, doc, stats):\n",
        "        self.lexicon = lex\n",
        "        self.inv = inv\n",
        "        self.doc = doc\n",
        "        self.stat = stats\n",
        "\n",
        "    def num_docs(self):\n",
        "        return self.stats['num_docs']\n",
        "\n",
        "    def get_posting(self, termid):\n",
        "        return InvertedIndex.PostingListIterator(self.inv['docids'][termid], self.inv['freqs'][termid], self.doc)\n",
        "\n",
        "    def get_termids(self, tokens):\n",
        "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
        "\n",
        "    def get_postings(self, termids):\n",
        "        return [self.get_posting(termid) for termid in termids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6a219298-ba9e-40af-a976-4305dd2abded"
      },
      "outputs": [],
      "source": [
        "inv_index = InvertedIndex(lex, inv, doc, stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa_COj90wg1F"
      },
      "source": [
        "TopQueue class, which stores the top  K  (score, docid) tuples, using an heap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2eaa7d65-1e50-46aa-a053-a7afd3b5a255"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "class TopQueue:\n",
        "    def __init__(self, k=10, threshold=0.0):\n",
        "        self.queue = []\n",
        "        self.k = k\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.queue)\n",
        "\n",
        "    def would_enter(self, score):\n",
        "        return score > self.threshold\n",
        "\n",
        "    def clear(self, new_threshold=None):\n",
        "        self.queue = []\n",
        "        if new_threshold:\n",
        "            self.threshold = new_threshold\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'<{self.size()} items, th={self.threshold} {self.queue}'\n",
        "\n",
        "    def insert(self, docid, score):\n",
        "        if score > self.threshold:\n",
        "            if self.size() >= self.k:\n",
        "                heapq.heapreplace(self.queue, (score, docid))\n",
        "            else:\n",
        "                heapq.heappush(self.queue, (score, docid))\n",
        "            if self.size() >= self.k:\n",
        "                self.threshold = max(self.threshold, self.queue[0][0])\n",
        "            return True\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok5kLF_fxjbQ"
      },
      "source": [
        "TAAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "c40a406f-cd24-4e41-adb0-e05f88a5cbe6"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def taat(postings, k=10):\n",
        "    A = defaultdict(float)\n",
        "    for posting in postings:\n",
        "        current_docid = posting.docid()\n",
        "        while current_docid != math.inf:\n",
        "            A[current_docid] += posting.score()\n",
        "            posting.next()\n",
        "            current_docid = posting.docid()\n",
        "    top = TopQueue(k)\n",
        "    for docid, score in A.items():\n",
        "        top.insert(docid, score)\n",
        "    return sorted(top.queue, reverse=True)\n",
        "\n",
        "def query_process(query, index):\n",
        "    qtokens = set(preprocess(query))\n",
        "    qtermids = index.get_termids(qtokens)\n",
        "    postings = index.get_postings(qtermids)\n",
        "    return taat(postings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh0BUYooxrqk"
      },
      "source": [
        "DAAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ddf92eec-2159-4d02-a34a-210ff6a8ee31"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def min_docid(postings):\n",
        "    min_docid = math.inf\n",
        "    for p in postings:\n",
        "        if not p.is_end_list():\n",
        "            min_docid = min(p.docid(), min_docid)\n",
        "    return min_docid\n",
        "\n",
        "def daat(postings, k=10):\n",
        "    top = TopQueue(k)\n",
        "    current_docid = min_docid(postings)\n",
        "    while current_docid != math.inf:\n",
        "        score = 0\n",
        "        next_docid = math.inf\n",
        "        for posting in postings:\n",
        "            if posting.docid() == current_docid:\n",
        "                score += posting.score()\n",
        "                posting.next()\n",
        "            if not posting.is_end_list():\n",
        "                next_docid = posting.docid()\n",
        "        top.insert(current_docid, score)\n",
        "        current_docid = next_docid\n",
        "    return sorted(top.queue, reverse=True)\n",
        "\n",
        "def query_process(query, index):\n",
        "    qtokens = set(preprocess(query))\n",
        "    qtermids = index.get_termids(qtokens)\n",
        "    postings = index.get_postings(qtermids)\n",
        "    return daat(postings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YccWSsil0ZQF",
        "outputId": "937f5b1e-9a31-499e-8206-c00ab1f8568d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://msmarco.z22.web.core.windows.net/msmarcoranking/queries.tar.gz\n",
            "To: /content/queries.tar.gz\n",
            "100%|██████████| 18.9M/18.9M [00:01<00:00, 15.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "url = 'https://msmarco.z22.web.core.windows.net/msmarcoranking/queries.tar.gz'\n",
        "gdown.download(url, 'queries.tar.gz', quiet=False)\n",
        "!tar -xzf queries.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "queries = pd.read_csv('queries.eval.tsv', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "4LD6h57eBXPJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MSMarcoQueries:\n",
        "    def __init__(self, df):\n",
        "        self.queries = [Query(row.query_id, row.text) for row in df.itertuples()]\n",
        "\n",
        "    def queries_iter(self):\n",
        "        return iter(self.queries)\n",
        "\n",
        "    def queries_count(self):\n",
        "        return len(self.queries)\n",
        "\n",
        "\n",
        "Query = namedtuple('Query', ['query_id', 'text'])"
      ],
      "metadata": {
        "id": "eyRIr9uF9-6M"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries.columns = ['query_id', 'text']\n",
        "queries_dataset = MSMarcoQueries(queries)"
      ],
      "metadata": {
        "id": "uBSQzl6j3W-E"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8QH1tdDyCxx",
        "outputId": "8e0253b5-4d1c-4bc2-c0af-7df0235e1689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101092\n"
          ]
        }
      ],
      "source": [
        "print(len(list(queries_dataset.queries_iter())))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@profile\n",
        "def query_processing(queries_iter, fn):\n",
        "    for q in queries_iter:\n",
        "        query = preprocess(q.text)\n",
        "        termids = inv_index.get_termids(query)\n",
        "        postings = inv_index.get_postings(termids)\n",
        "        res = fn(postings)"
      ],
      "metadata": {
        "id": "u-UQcCcTkNo-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_processing(queries_dataset.queries_iter(), taat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "1Nn02ZlSkiUP",
        "outputId": "76de8ac6-4d0e-4e28-ecc7-7ddbbd11b9de"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-71dd1dd808e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueries_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-208e0edc74c8>\u001b[0m in \u001b[0;36mf_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-9063002de8e5>\u001b[0m in \u001b[0;36mquery_processing\u001b[0;34m(queries_iter, fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtermids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_termids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpostings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_postings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpostings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-f2bcfb7a9f1a>\u001b[0m in \u001b[0;36mtaat\u001b[0;34m(postings, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcurrent_docid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent_docid\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_docid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mposting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcurrent_docid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-3e3d3be45258>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_end_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_processing(queries_dataset.queries_iter(), daat)"
      ],
      "metadata": {
        "id": "KuEay64mkrR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uBbdTl7oBcO"
      },
      "source": [
        "Now build up the index for the MSMARCO collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFodt2eRoLXx"
      },
      "outputs": [],
      "source": [
        "# create a df with the first 10 rows\n",
        "#df_cut = df.head(10) # TODO : REMOVE THIS\n",
        "\n",
        "dataset = MSMarcoDataset(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIBvuNv8oPS3"
      },
      "source": [
        "The index is built only if a pickled version isn't already present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teujB76HoAE5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "try: # try to open the pickled files, else build the index\n",
        "    with open('./lex.pkl', 'rb') as f:\n",
        "        lex = pickle.load(f)\n",
        "    with open('./inv.pkl', 'rb') as f:\n",
        "        inv = pickle.load(f)\n",
        "    with open('./doc.pkl', 'rb') as f:\n",
        "        doc = pickle.load(f)\n",
        "    with open('./stats.pkl', 'rb') as f:\n",
        "        stats = pickle.load(f)\n",
        "    print(\"Index loaded from pickles\")\n",
        "\n",
        "except:\n",
        "    lex, inv, doc, stats = build_index(dataset)\n",
        "\n",
        "    # pickle lex, inv, doc, stats\n",
        "    with open('./lex.pkl', 'wb') as f:\n",
        "        pickle.dump(lex, f)\n",
        "\n",
        "    with open('./inv.pkl','wb') as f:\n",
        "        pickle.dump(inv, f)\n",
        "\n",
        "    with open('./doc.pkl', 'wb') as f:\n",
        "        pickle.dump(doc, f)\n",
        "\n",
        "    with open('./stats.pkl', 'wb') as f:\n",
        "        pickle.dump(stats, f)\n",
        "\n",
        "    print(\"Index built and pickled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEd4N3FkperO"
      },
      "outputs": [],
      "source": [
        "print(lex)\n",
        "print(inv)\n",
        "print(doc)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inv_index = InvertedIndex(lex, inv, doc, stats)"
      ],
      "metadata": {
        "id": "Xaew03X77sqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_processing(queries_dataset.queries_iter(), taat)"
      ],
      "metadata": {
        "id": "nGNXBkpg7rl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query_processing(queries_dataset.queries_iter(), daat)"
      ],
      "metadata": {
        "id": "XVX0igcQ7qGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ec2e40f9cc34efab5544a7727b0686a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b810509205ea45f699bd3848f998a187",
              "IPY_MODEL_78a09b740453455a99e14d6109919c52",
              "IPY_MODEL_17ec15452b0a435bb1d4040d6b8c8b85"
            ],
            "layout": "IPY_MODEL_292fd00a1b524da2a79f5273768e06d6"
          }
        },
        "b810509205ea45f699bd3848f998a187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e030f29b2cf348d3a2f29aef2a0e5fcb",
            "placeholder": "​",
            "style": "IPY_MODEL_831e8fd443684346ad096bdd300657d7",
            "value": "Indexing: 100%"
          }
        },
        "78a09b740453455a99e14d6109919c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f264f8a61924e879806974dcd2103c8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aba07292495142c4be08ede74d9b7637",
            "value": 3
          }
        },
        "17ec15452b0a435bb1d4040d6b8c8b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2159ab6a19334335ad145938f874bbbb",
            "placeholder": "​",
            "style": "IPY_MODEL_29ea010f911e48a3b0550a2b21d63345",
            "value": " 3/3 [00:00&lt;00:00, 85.49it/s]"
          }
        },
        "292fd00a1b524da2a79f5273768e06d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e030f29b2cf348d3a2f29aef2a0e5fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831e8fd443684346ad096bdd300657d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f264f8a61924e879806974dcd2103c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba07292495142c4be08ede74d9b7637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2159ab6a19334335ad145938f874bbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ea010f911e48a3b0550a2b21d63345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}